{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "385e43a763cf2a2e696526612151db7c079f8909"
   },
   "source": [
    "#Code by Gana Teja Akula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "59473a37053f45e5fa614894494897f4e3b0f36e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "133377356f22c2ca5e37b5a969f6d550e889f086"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "39cff8696636f21dd5b26854b6d608a73a635345"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/sign_mnist_train.csv')\n",
    "test = pd.read_csv('../input/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1704cf375513a33e8c0d963feebca7b783b5a0b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>165</td>\n",
       "      <td>159</td>\n",
       "      <td>166</td>\n",
       "      <td>168</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>169</td>\n",
       "      <td>111</td>\n",
       "      <td>121</td>\n",
       "      <td>129</td>\n",
       "      <td>135</td>\n",
       "      <td>141</td>\n",
       "      <td>144</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>154</td>\n",
       "      <td>157</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>205</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>142</td>\n",
       "      <td>151</td>\n",
       "      <td>160</td>\n",
       "      <td>172</td>\n",
       "      <td>196</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>135</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>79</td>\n",
       "      <td>176</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>153</td>\n",
       "      <td>152</td>\n",
       "      <td>151</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>146</td>\n",
       "      <td>144</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>138</td>\n",
       "      <td>92</td>\n",
       "      <td>108</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>78</td>\n",
       "      <td>120</td>\n",
       "      <td>157</td>\n",
       "      <td>168</td>\n",
       "      <td>107</td>\n",
       "      <td>99</td>\n",
       "      <td>121</td>\n",
       "      <td>133</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>120</td>\n",
       "      <td>135</td>\n",
       "      <td>116</td>\n",
       "      <td>95</td>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "      <td>86</td>\n",
       "      <td>139</td>\n",
       "      <td>173</td>\n",
       "      <td>200</td>\n",
       "      <td>185</td>\n",
       "      <td>175</td>\n",
       "      <td>198</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>94</td>\n",
       "      <td>140</td>\n",
       "      <td>133</td>\n",
       "      <td>84</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>193</td>\n",
       "      <td>198</td>\n",
       "      <td>166</td>\n",
       "      <td>132</td>\n",
       "      <td>114</td>\n",
       "      <td>89</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>132</td>\n",
       "      <td>188</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>206</td>\n",
       "      <td>205</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>209</td>\n",
       "      <td>207</td>\n",
       "      <td>208</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>198</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>171</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>...</td>\n",
       "      <td>247</td>\n",
       "      <td>242</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>229</td>\n",
       "      <td>227</td>\n",
       "      <td>225</td>\n",
       "      <td>223</td>\n",
       "      <td>221</td>\n",
       "      <td>220</td>\n",
       "      <td>216</td>\n",
       "      <td>58</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>255</td>\n",
       "      <td>237</td>\n",
       "      <td>239</td>\n",
       "      <td>237</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>187</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>127</td>\n",
       "      <td>129</td>\n",
       "      <td>134</td>\n",
       "      <td>145</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>179</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>175</td>\n",
       "      <td>199</td>\n",
       "      <td>178</td>\n",
       "      <td>152</td>\n",
       "      <td>136</td>\n",
       "      <td>130</td>\n",
       "      <td>136</td>\n",
       "      <td>150</td>\n",
       "      <td>118</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>76</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2    ...     pixel782  pixel783  pixel784\n",
       "0      3     107     118    ...          204       203       202\n",
       "1      6     155     157    ...          103       135       149\n",
       "2      2     187     188    ...          195       194       195\n",
       "3      2     211     211    ...          222       229       163\n",
       "4     13     164     167    ...          163       164       179\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8c2df551d7a771cb4fdc25b574a48a1652f251f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 785)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c08c24f5b0f18610feb7fbf0d7772792f78dac8d"
   },
   "outputs": [],
   "source": [
    "labels = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "5b97bf1309270da6695095e295886882e8c3c8af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_val = np.array(labels)\n",
    "np.unique(unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "cf73d03f610be9f134a3ee5e35301b1da4626d02"
   },
   "outputs": [],
   "source": [
    "train.drop('label', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b25a4af6ed60a970d5f530f4c94aca2e0c2554de"
   },
   "outputs": [],
   "source": [
    "images = train.values\n",
    "images = np.array([np.reshape(i, (28, 28)) for i in images])\n",
    "images = np.array([i.flatten() for i in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "796cf96b649f38bdece4403bf719e5788857f296"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binrizer = LabelBinarizer()\n",
    "labels = label_binrizer.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "0e6e3147f9d104a39ca91b75e5e78d44b07b9b35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "a2998dd21e53a4f15514277995491eafc5f6b235"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "8195b569b6b66f7f03d510b26eb8941a6eff8f96"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "c844dbe8b17ca2926268369d41b2973ffe5e9070"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "1cb372496acf0b6e5ffb4a951d4445929fed7706"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "9556ccbe5f61082d473f9fbafa1f741e8767a496"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feab457c160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "e486c080ea745082f91ca1d2cfc0aac975afdd3b"
   },
   "outputs": [],
   "source": [
    "test_labels = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "928db66ba635ba5cfc2726d8999221b40ccb65c6"
   },
   "outputs": [],
   "source": [
    "test.drop('label', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "7784e23a832e38afafcf619b779a43f10a1ff324"
   },
   "outputs": [],
   "source": [
    "test_images = test.values\n",
    "test_images = np.array([np.reshape(i, (28, 28)) for i in test_images])\n",
    "test_images = np.array([i.flatten() for i in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "d7b3c7af0b9d568322311fce747bf9e6dc38a7e3"
   },
   "outputs": [],
   "source": [
    "test_labels = label_binrizer.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "ece82abdeed075224b5d83ca26ff3d23338a8e89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "f3ce64a4b948d953cfb30bfee2da40c91c097149"
   },
   "outputs": [],
   "source": [
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "f052e644cc78e783b928c28f2fdaf489d02db2a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "5ea8e028946c030cc36a7bab5eb0e2c0dd8eb84c"
   },
   "outputs": [],
   "source": [
    "import Modelclass as Modelclass\n",
    "import GeneticVector as GeneticVector\n",
    "best_hyperparameters=[]\n",
    "accuracy=0\n",
    "total_tries=[]\n",
    "count=0\n",
    "acckeys=[]\n",
    "accvals=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "7bc77968dbdaa173f11cb858cddca76a65107111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 64, 64, 32, 'tanh', 'tanh', 'tanh', 'tanh', <keras.optimizers.Adam object at 0x7feab4e8cb70>, 64, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 9s 473us/step - loss: 1.8591 - acc: 0.4767 - val_loss: 0.8895 - val_acc: 0.7831\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 0.5605 - acc: 0.8785 - val_loss: 0.2721 - val_acc: 0.9620\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 0.1988 - acc: 0.9772 - val_loss: 0.0847 - val_acc: 0.9947\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 0.0830 - acc: 0.9953 - val_loss: 0.0358 - val_acc: 0.9999\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 0.0421 - acc: 0.9992 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 0.0257 - acc: 0.9999 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 4s 229us/step - loss: 0.0179 - acc: 0.9998 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 0.0122 - acc: 0.9999 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 4s 229us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 4s 229us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 4s 231us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 9.2631e-04 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 0.0389 - acc: 0.9908 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 8.8234e-04 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 4s 231us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 5.3746e-04 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 4.2370e-04 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 4s 233us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 3.2925e-04 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.8621e-04 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.3304e-04 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.8336e-04 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.4782e-04 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 9.6977e-04 - acc: 1.0000 - val_loss: 1.3931e-04 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.5054e-04 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 8.3670e-04 - acc: 1.0000 - val_loss: 1.0121e-04 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 7.5476e-04 - acc: 1.0000 - val_loss: 7.6150e-05 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 4s 229us/step - loss: 6.7000e-04 - acc: 1.0000 - val_loss: 7.6501e-05 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 0.0518 - acc: 0.9844 - val_loss: 0.0168 - val_acc: 0.9961\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 4s 231us/step - loss: 0.0054 - acc: 0.9991 - val_loss: 3.0134e-04 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 0.0015 - acc: 0.9999 - val_loss: 2.2023e-04 - val_acc: 1.0000\n",
      "[16, 32, 16, 128, 'relu', 'tanh', 'tanh', 'relu', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 128, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 2s 87us/step - loss: 3.1767 - acc: 0.0450 - val_loss: 3.1748 - val_acc: 0.0418\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 3.1738 - acc: 0.0472 - val_loss: 3.1727 - val_acc: 0.0414\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 1s 71us/step - loss: 3.1710 - acc: 0.0500 - val_loss: 3.1702 - val_acc: 0.0438\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 1s 72us/step - loss: 3.1692 - acc: 0.0516 - val_loss: 3.1678 - val_acc: 0.0467\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 1s 74us/step - loss: 3.1662 - acc: 0.0541 - val_loss: 3.1645 - val_acc: 0.0544\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 1s 72us/step - loss: 3.1625 - acc: 0.0645 - val_loss: 3.1601 - val_acc: 0.0749\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 3.1571 - acc: 0.0745 - val_loss: 3.1543 - val_acc: 0.0932\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 3.1506 - acc: 0.0875 - val_loss: 3.1467 - val_acc: 0.1101\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 3.1418 - acc: 0.0967 - val_loss: 3.1364 - val_acc: 0.1139\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 1s 74us/step - loss: 3.1292 - acc: 0.1053 - val_loss: 3.1220 - val_acc: 0.1145\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 3.1129 - acc: 0.1118 - val_loss: 3.1009 - val_acc: 0.1184\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 3.0876 - acc: 0.1133 - val_loss: 3.0701 - val_acc: 0.1214\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 3.0534 - acc: 0.1139 - val_loss: 3.0279 - val_acc: 0.1244\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 3.0054 - acc: 0.1191 - val_loss: 2.9736 - val_acc: 0.1243\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 2.9506 - acc: 0.1215 - val_loss: 2.9142 - val_acc: 0.1359\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 2.8947 - acc: 0.1319 - val_loss: 2.8554 - val_acc: 0.1522\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 2.8376 - acc: 0.1442 - val_loss: 2.7940 - val_acc: 0.1736\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 2.7796 - acc: 0.1631 - val_loss: 2.7342 - val_acc: 0.2002\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 2.7234 - acc: 0.1768 - val_loss: 2.6669 - val_acc: 0.2206\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 2.6594 - acc: 0.1954 - val_loss: 2.5970 - val_acc: 0.2397\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 2.5922 - acc: 0.2124 - val_loss: 2.5206 - val_acc: 0.2525\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 2.5183 - acc: 0.2336 - val_loss: 2.4503 - val_acc: 0.2821\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 1s 74us/step - loss: 2.4374 - acc: 0.2548 - val_loss: 2.3720 - val_acc: 0.3006\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 2.3675 - acc: 0.2717 - val_loss: 2.2828 - val_acc: 0.3160\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 2.2930 - acc: 0.2873 - val_loss: 2.2368 - val_acc: 0.3206\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 2.2251 - acc: 0.3099 - val_loss: 2.1624 - val_acc: 0.3640\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 2.1590 - acc: 0.3230 - val_loss: 2.0763 - val_acc: 0.3955\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 2.1018 - acc: 0.3454 - val_loss: 2.0336 - val_acc: 0.3882\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 2.0444 - acc: 0.3522 - val_loss: 2.0380 - val_acc: 0.3896\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 1.9914 - acc: 0.3789 - val_loss: 1.9284 - val_acc: 0.4167\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 1.9388 - acc: 0.3881 - val_loss: 1.8955 - val_acc: 0.4163\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 1.8879 - acc: 0.4031 - val_loss: 1.8677 - val_acc: 0.4228\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 1s 77us/step - loss: 1.8404 - acc: 0.4174 - val_loss: 1.7820 - val_acc: 0.4492\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 1.7925 - acc: 0.4290 - val_loss: 1.7991 - val_acc: 0.4222\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 1.7443 - acc: 0.4419 - val_loss: 1.7832 - val_acc: 0.4435\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 1.6986 - acc: 0.4569 - val_loss: 1.6267 - val_acc: 0.4927\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 1s 75us/step - loss: 1.6513 - acc: 0.4669 - val_loss: 1.5872 - val_acc: 0.5110\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 1.6047 - acc: 0.4802 - val_loss: 1.5470 - val_acc: 0.5132\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 1.5660 - acc: 0.4961 - val_loss: 1.6321 - val_acc: 0.4666\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 1s 76us/step - loss: 1.5186 - acc: 0.5049 - val_loss: 1.4214 - val_acc: 0.5561\n",
      "[32, 128, 32, 128, 'tanh', 'relu', 'sigmoid', 'relu', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 256, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 2s 110us/step - loss: 3.1957 - acc: 0.0425 - val_loss: 3.1836 - val_acc: 0.0488\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1894 - acc: 0.0425 - val_loss: 3.1788 - val_acc: 0.0488\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1845 - acc: 0.0454 - val_loss: 3.1769 - val_acc: 0.0488\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 2s 80us/step - loss: 3.1822 - acc: 0.0431 - val_loss: 3.1762 - val_acc: 0.0488\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 2s 81us/step - loss: 3.1803 - acc: 0.0479 - val_loss: 3.1757 - val_acc: 0.0488\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 2s 80us/step - loss: 3.1801 - acc: 0.0460 - val_loss: 3.1755 - val_acc: 0.0488\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 2s 80us/step - loss: 3.1800 - acc: 0.0459 - val_loss: 3.1754 - val_acc: 0.0466\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1807 - acc: 0.0478 - val_loss: 3.1751 - val_acc: 0.0511\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 2s 80us/step - loss: 3.1801 - acc: 0.0456 - val_loss: 3.1751 - val_acc: 0.0422\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 2s 80us/step - loss: 3.1787 - acc: 0.0464 - val_loss: 3.1749 - val_acc: 0.0493\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 2s 81us/step - loss: 3.1777 - acc: 0.0472 - val_loss: 3.1747 - val_acc: 0.0589\n",
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 2s 80us/step - loss: 3.1786 - acc: 0.0434 - val_loss: 3.1745 - val_acc: 0.0484\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1778 - acc: 0.0470 - val_loss: 3.1746 - val_acc: 0.0418\n",
      "Epoch 14/30\n",
      "19218/19218 [==============================] - 2s 82us/step - loss: 3.1786 - acc: 0.0470 - val_loss: 3.1743 - val_acc: 0.0524\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 2s 80us/step - loss: 3.1780 - acc: 0.0455 - val_loss: 3.1744 - val_acc: 0.0419\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 2s 81us/step - loss: 3.1787 - acc: 0.0454 - val_loss: 3.1742 - val_acc: 0.0482\n",
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1766 - acc: 0.0490 - val_loss: 3.1741 - val_acc: 0.0448\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1773 - acc: 0.0471 - val_loss: 3.1740 - val_acc: 0.0549\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 2s 80us/step - loss: 3.1773 - acc: 0.0469 - val_loss: 3.1739 - val_acc: 0.0465\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1749 - acc: 0.0494 - val_loss: 3.1737 - val_acc: 0.0460\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1768 - acc: 0.0478 - val_loss: 3.1736 - val_acc: 0.0430\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1757 - acc: 0.0464 - val_loss: 3.1734 - val_acc: 0.0514\n",
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1756 - acc: 0.0518 - val_loss: 3.1733 - val_acc: 0.0592\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 2s 78us/step - loss: 3.1762 - acc: 0.0476 - val_loss: 3.1732 - val_acc: 0.0674\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 1s 78us/step - loss: 3.1752 - acc: 0.0504 - val_loss: 3.1730 - val_acc: 0.0651\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 2s 78us/step - loss: 3.1754 - acc: 0.0492 - val_loss: 3.1730 - val_acc: 0.0582\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 1s 78us/step - loss: 3.1747 - acc: 0.0523 - val_loss: 3.1729 - val_acc: 0.0580\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 1s 78us/step - loss: 3.1749 - acc: 0.0487 - val_loss: 3.1728 - val_acc: 0.0548\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1743 - acc: 0.0487 - val_loss: 3.1726 - val_acc: 0.0548\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 2s 79us/step - loss: 3.1736 - acc: 0.0510 - val_loss: 3.1724 - val_acc: 0.0614\n",
      "[128, 32, 32, 64, 'tanh', 'relu', 'sigmoid', 'tanh', <keras.optimizers.Adam object at 0x7feab4e8cb70>, 64, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 4s 229us/step - loss: 2.9630 - acc: 0.1002 - val_loss: 2.6123 - val_acc: 0.2118\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 1.7144 - acc: 0.4625 - val_loss: 0.8888 - val_acc: 0.7284\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.6071 - acc: 0.8219 - val_loss: 0.3496 - val_acc: 0.9156\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.2688 - acc: 0.9383 - val_loss: 0.1665 - val_acc: 0.9709\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.1296 - acc: 0.9791 - val_loss: 0.0785 - val_acc: 0.9905\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0689 - acc: 0.9930 - val_loss: 0.0464 - val_acc: 0.9967\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 0.0401 - acc: 0.9971 - val_loss: 0.0225 - val_acc: 0.9995\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0267 - acc: 0.9991 - val_loss: 0.0149 - val_acc: 0.9995\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0182 - acc: 0.9994 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0134 - acc: 0.9998 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0087 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9994\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 0.0060 - acc: 0.9999 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0230 - acc: 0.9939 - val_loss: 0.0082 - val_acc: 0.9993\n",
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0069 - acc: 0.9992 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 8.9178e-04 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.8781e-04 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.8863e-04 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.6800e-04 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 4.7982e-04 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.0340 - acc: 0.9892 - val_loss: 0.0040 - val_acc: 0.9996\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0026 - acc: 0.9999 - val_loss: 7.4716e-04 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.5427e-04 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 4.8286e-04 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 9.5440e-04 - acc: 1.0000 - val_loss: 5.3181e-04 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 7.9302e-04 - acc: 1.0000 - val_loss: 4.1343e-04 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 7.7656e-04 - acc: 1.0000 - val_loss: 3.0229e-04 - val_acc: 1.0000\n",
      "[64, 16, 16, 128, 'relu', 'sigmoid', 'tanh', 'sigmoid', <keras.optimizers.Adamax object at 0x7feab4e8cf28>, 128, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 2s 124us/step - loss: 3.2368 - acc: 0.0400 - val_loss: 3.1824 - val_acc: 0.0484\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.2080 - acc: 0.0436 - val_loss: 3.1777 - val_acc: 0.0418\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1965 - acc: 0.0450 - val_loss: 3.1738 - val_acc: 0.0590\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1823 - acc: 0.0498 - val_loss: 3.1514 - val_acc: 0.0674\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 3.1405 - acc: 0.0692 - val_loss: 3.0856 - val_acc: 0.1088\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 3.0423 - acc: 0.0938 - val_loss: 2.9409 - val_acc: 0.1236\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 2.8710 - acc: 0.1255 - val_loss: 2.7297 - val_acc: 0.1749\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 2.6609 - acc: 0.1799 - val_loss: 2.4875 - val_acc: 0.2615\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 2.4174 - acc: 0.2448 - val_loss: 2.2408 - val_acc: 0.3171\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 2.1683 - acc: 0.3202 - val_loss: 2.0072 - val_acc: 0.3960\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 1.9472 - acc: 0.3815 - val_loss: 1.7650 - val_acc: 0.4591\n",
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 1.7286 - acc: 0.4510 - val_loss: 1.5668 - val_acc: 0.5161\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 1.5491 - acc: 0.5048 - val_loss: 1.4270 - val_acc: 0.5481\n",
      "Epoch 14/30\n",
      "19218/19218 [==============================] - 2s 94us/step - loss: 1.4089 - acc: 0.5431 - val_loss: 1.2808 - val_acc: 0.5881\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 2s 94us/step - loss: 1.2852 - acc: 0.5834 - val_loss: 1.1836 - val_acc: 0.6156\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 2s 94us/step - loss: 1.1771 - acc: 0.6111 - val_loss: 1.0743 - val_acc: 0.6456\n",
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 1.0889 - acc: 0.6385 - val_loss: 0.9884 - val_acc: 0.6768\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 1.0056 - acc: 0.6674 - val_loss: 0.9509 - val_acc: 0.6813\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.9432 - acc: 0.6840 - val_loss: 0.8548 - val_acc: 0.7198\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.8783 - acc: 0.7057 - val_loss: 0.8116 - val_acc: 0.7351\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.8252 - acc: 0.7278 - val_loss: 0.7569 - val_acc: 0.7548\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.7714 - acc: 0.7460 - val_loss: 0.7001 - val_acc: 0.7701\n",
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.7316 - acc: 0.7583 - val_loss: 0.6685 - val_acc: 0.7790\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.6926 - acc: 0.7673 - val_loss: 0.6431 - val_acc: 0.7770\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.6492 - acc: 0.7807 - val_loss: 0.5813 - val_acc: 0.8145\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.6121 - acc: 0.7955 - val_loss: 0.5578 - val_acc: 0.8096\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.5719 - acc: 0.8105 - val_loss: 0.5197 - val_acc: 0.8309\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.5412 - acc: 0.8201 - val_loss: 0.4816 - val_acc: 0.8385\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.5117 - acc: 0.8309 - val_loss: 0.4634 - val_acc: 0.8544\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.4801 - acc: 0.8440 - val_loss: 0.4275 - val_acc: 0.8583\n",
      "[16, 32, 128, 16, 'relu', 'sigmoid', 'relu', 'sigmoid', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 64, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.2379 - acc: 0.0419 - val_loss: 3.1957 - val_acc: 0.0381\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 2s 126us/step - loss: 3.1934 - acc: 0.0414 - val_loss: 3.1820 - val_acc: 0.0381\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 3s 131us/step - loss: 3.1836 - acc: 0.0426 - val_loss: 3.1782 - val_acc: 0.0399\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1798 - acc: 0.0444 - val_loss: 3.1770 - val_acc: 0.0418\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1786 - acc: 0.0462 - val_loss: 3.1765 - val_acc: 0.0418\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1789 - acc: 0.0463 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1782 - acc: 0.0442 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1768 - acc: 0.0453 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 3s 137us/step - loss: 3.1780 - acc: 0.0419 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1773 - acc: 0.0466 - val_loss: 3.1759 - val_acc: 0.0418\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1770 - acc: 0.0437 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 3s 137us/step - loss: 3.1773 - acc: 0.0448 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1767 - acc: 0.0473 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1762 - acc: 0.0471 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1766 - acc: 0.0440 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1765 - acc: 0.0464 - val_loss: 3.1759 - val_acc: 0.0464\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1763 - acc: 0.0469 - val_loss: 3.1759 - val_acc: 0.0469\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1759 - acc: 0.0455 - val_loss: 3.1759 - val_acc: 0.0490\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1766 - acc: 0.0443 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1765 - acc: 0.0453 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 3s 132us/step - loss: 3.1764 - acc: 0.0458 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 3s 133us/step - loss: 3.1760 - acc: 0.0463 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1759 - acc: 0.0458 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1761 - acc: 0.0449 - val_loss: 3.1758 - val_acc: 0.0412\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1761 - acc: 0.0461 - val_loss: 3.1759 - val_acc: 0.0416\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1761 - acc: 0.0454 - val_loss: 3.1758 - val_acc: 0.0415\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1762 - acc: 0.0450 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1757 - acc: 0.0458 - val_loss: 3.1758 - val_acc: 0.0494\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1757 - acc: 0.0461 - val_loss: 3.1758 - val_acc: 0.0494\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1763 - acc: 0.0487 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1759 - acc: 0.0468 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1758 - acc: 0.0480 - val_loss: 3.1758 - val_acc: 0.0490\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1762 - acc: 0.0455 - val_loss: 3.1758 - val_acc: 0.0432\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1760 - acc: 0.0457 - val_loss: 3.1758 - val_acc: 0.0490\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 3s 137us/step - loss: 3.1760 - acc: 0.0464 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1759 - acc: 0.0465 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1757 - acc: 0.0448 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1761 - acc: 0.0466 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1755 - acc: 0.0474 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1760 - acc: 0.0463 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 3.1755 - acc: 0.0446 - val_loss: 3.1758 - val_acc: 0.0492\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1758 - acc: 0.0464 - val_loss: 3.1758 - val_acc: 0.0487\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 3s 138us/step - loss: 3.1755 - acc: 0.0463 - val_loss: 3.1758 - val_acc: 0.0489\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1756 - acc: 0.0478 - val_loss: 3.1758 - val_acc: 0.0459\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 3s 136us/step - loss: 3.1757 - acc: 0.0473 - val_loss: 3.1758 - val_acc: 0.0460\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1755 - acc: 0.0454 - val_loss: 3.1758 - val_acc: 0.0460\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1755 - acc: 0.0472 - val_loss: 3.1758 - val_acc: 0.0449\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1756 - acc: 0.0480 - val_loss: 3.1758 - val_acc: 0.0422\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1757 - acc: 0.0465 - val_loss: 3.1758 - val_acc: 0.0416\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1760 - acc: 0.0452 - val_loss: 3.1758 - val_acc: 0.0425\n",
      "[64, 64, 128, 128, 'sigmoid', 'relu', 'tanh', 'relu', <keras.optimizers.Adamax object at 0x7feab4e8cf28>, 64, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 5s 246us/step - loss: 3.1781 - acc: 0.0440 - val_loss: 3.1768 - val_acc: 0.0418\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.1762 - acc: 0.0457 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.1761 - acc: 0.0454 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.1761 - acc: 0.0470 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 3.1760 - acc: 0.0460 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.1759 - acc: 0.0450 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 3.1760 - acc: 0.0443 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.1759 - acc: 0.0465 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 3.1760 - acc: 0.0437 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.1759 - acc: 0.0434 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 3.1758 - acc: 0.0468 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1758 - acc: 0.0461 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 3.1759 - acc: 0.0455 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1758 - acc: 0.0477 - val_loss: 3.1759 - val_acc: 0.0418\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 3.1759 - acc: 0.0457 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1759 - acc: 0.0461 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 4s 195us/step - loss: 3.1759 - acc: 0.0450 - val_loss: 3.1761 - val_acc: 0.0418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1758 - acc: 0.0462 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1758 - acc: 0.0451 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 3.1757 - acc: 0.0455 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 3.1758 - acc: 0.0468 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1758 - acc: 0.0459 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.1756 - acc: 0.0468 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1757 - acc: 0.0454 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1758 - acc: 0.0459 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1757 - acc: 0.0455 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1757 - acc: 0.0459 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 4s 195us/step - loss: 3.1757 - acc: 0.0450 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1757 - acc: 0.0461 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 3.1757 - acc: 0.0452 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1757 - acc: 0.0460 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 3.1757 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1757 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1757 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 3.1757 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 4s 196us/step - loss: 3.1756 - acc: 0.0445 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.1756 - acc: 0.0469 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "[128, 16, 64, 32, 'tanh', 'sigmoid', 'sigmoid', 'sigmoid', <keras.optimizers.Adam object at 0x7feab4e8cb70>, 128, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 4s 187us/step - loss: 3.1847 - acc: 0.0477 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1742 - acc: 0.0527 - val_loss: 3.1637 - val_acc: 0.0887\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.0585 - acc: 0.0855 - val_loss: 2.8942 - val_acc: 0.1111\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 2.8392 - acc: 0.1132 - val_loss: 2.7005 - val_acc: 0.1613\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 2.6597 - acc: 0.1449 - val_loss: 2.5071 - val_acc: 0.2123\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 2.4543 - acc: 0.2079 - val_loss: 2.2945 - val_acc: 0.2868\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 2.2351 - acc: 0.2674 - val_loss: 2.0676 - val_acc: 0.3451\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 1.9989 - acc: 0.3381 - val_loss: 1.8536 - val_acc: 0.3795\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 1.8023 - acc: 0.3970 - val_loss: 1.6263 - val_acc: 0.4774\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 1.6437 - acc: 0.4493 - val_loss: 1.4738 - val_acc: 0.5305\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 1.5166 - acc: 0.4846 - val_loss: 1.3606 - val_acc: 0.5605\n",
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 3s 138us/step - loss: 1.4075 - acc: 0.5257 - val_loss: 1.2311 - val_acc: 0.6133\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 1.2876 - acc: 0.5713 - val_loss: 1.1390 - val_acc: 0.6589\n",
      "Epoch 14/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 1.2062 - acc: 0.6017 - val_loss: 1.0610 - val_acc: 0.6836\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 1.1196 - acc: 0.6309 - val_loss: 0.9614 - val_acc: 0.7238\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 1.0449 - acc: 0.6553 - val_loss: 0.8923 - val_acc: 0.7419\n",
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 0.9694 - acc: 0.6832 - val_loss: 0.8266 - val_acc: 0.7549\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 0.9094 - acc: 0.7049 - val_loss: 0.7832 - val_acc: 0.7726\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 0.8517 - acc: 0.7249 - val_loss: 0.7019 - val_acc: 0.8025\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 0.7879 - acc: 0.7445 - val_loss: 0.6536 - val_acc: 0.8173\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 3s 138us/step - loss: 0.7355 - acc: 0.7644 - val_loss: 0.6158 - val_acc: 0.8277\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 0.6832 - acc: 0.7841 - val_loss: 0.5494 - val_acc: 0.8521\n",
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 0.6393 - acc: 0.7990 - val_loss: 0.5118 - val_acc: 0.8559\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 3s 138us/step - loss: 0.5950 - acc: 0.8162 - val_loss: 0.4679 - val_acc: 0.8791\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 3s 138us/step - loss: 0.5601 - acc: 0.8276 - val_loss: 0.4461 - val_acc: 0.8854\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 3s 138us/step - loss: 0.5221 - acc: 0.8413 - val_loss: 0.3947 - val_acc: 0.8985\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 0.4834 - acc: 0.8538 - val_loss: 0.3672 - val_acc: 0.9024\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 0.4511 - acc: 0.8669 - val_loss: 0.3419 - val_acc: 0.9162\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 0.4249 - acc: 0.8771 - val_loss: 0.3077 - val_acc: 0.9289\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 3s 138us/step - loss: 0.3908 - acc: 0.8884 - val_loss: 0.2987 - val_acc: 0.9267\n",
      "[16, 64, 32, 32, 'relu', 'relu', 'tanh', 'relu', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 256, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 3.1752 - acc: 0.0502 - val_loss: 3.1729 - val_acc: 0.0609\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1721 - acc: 0.0530 - val_loss: 3.1711 - val_acc: 0.0523\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 3.1707 - acc: 0.0565 - val_loss: 3.1698 - val_acc: 0.0606\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1693 - acc: 0.0635 - val_loss: 3.1684 - val_acc: 0.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 3.1680 - acc: 0.0679 - val_loss: 3.1671 - val_acc: 0.0970\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 3.1661 - acc: 0.0777 - val_loss: 3.1651 - val_acc: 0.0941\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1643 - acc: 0.0824 - val_loss: 3.1633 - val_acc: 0.0949\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 3.1628 - acc: 0.0821 - val_loss: 3.1615 - val_acc: 0.1157\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1603 - acc: 0.0873 - val_loss: 3.1590 - val_acc: 0.1116\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1581 - acc: 0.0895 - val_loss: 3.1564 - val_acc: 0.1078\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 1s 53us/step - loss: 3.1551 - acc: 0.0909 - val_loss: 3.1535 - val_acc: 0.1257\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1523 - acc: 0.0953 - val_loss: 3.1499 - val_acc: 0.1198\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 3.1478 - acc: 0.0966 - val_loss: 3.1460 - val_acc: 0.1306\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1438 - acc: 0.1001 - val_loss: 3.1406 - val_acc: 0.1204\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1380 - acc: 0.1020 - val_loss: 3.1350 - val_acc: 0.1080\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1320 - acc: 0.1025 - val_loss: 3.1289 - val_acc: 0.1400\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 3.1249 - acc: 0.1072 - val_loss: 3.1191 - val_acc: 0.1378\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.1156 - acc: 0.1093 - val_loss: 3.1106 - val_acc: 0.1135\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 3.1059 - acc: 0.1119 - val_loss: 3.0970 - val_acc: 0.1207\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.0917 - acc: 0.1168 - val_loss: 3.0824 - val_acc: 0.1182\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 1s 54us/step - loss: 3.0763 - acc: 0.1184 - val_loss: 3.0630 - val_acc: 0.1549\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 1s 53us/step - loss: 3.0573 - acc: 0.1216 - val_loss: 3.0452 - val_acc: 0.1424\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.0303 - acc: 0.1255 - val_loss: 3.0126 - val_acc: 0.1724\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 3.0025 - acc: 0.1347 - val_loss: 2.9799 - val_acc: 0.1527\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.9672 - acc: 0.1365 - val_loss: 2.9498 - val_acc: 0.1686\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.9285 - acc: 0.1445 - val_loss: 2.8909 - val_acc: 0.1586\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.8788 - acc: 0.1548 - val_loss: 2.8409 - val_acc: 0.1815\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.8194 - acc: 0.1678 - val_loss: 2.7656 - val_acc: 0.1969\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.7662 - acc: 0.1743 - val_loss: 2.7119 - val_acc: 0.1797\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.7108 - acc: 0.1828 - val_loss: 2.7091 - val_acc: 0.1873\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.6495 - acc: 0.1967 - val_loss: 2.6563 - val_acc: 0.1856\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.5935 - acc: 0.2062 - val_loss: 2.6099 - val_acc: 0.2225\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.5495 - acc: 0.2116 - val_loss: 2.5474 - val_acc: 0.2352\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.5035 - acc: 0.2181 - val_loss: 2.4984 - val_acc: 0.2313\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.4532 - acc: 0.2307 - val_loss: 2.3994 - val_acc: 0.2430\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.4225 - acc: 0.2334 - val_loss: 2.4881 - val_acc: 0.2174\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.3885 - acc: 0.2404 - val_loss: 2.4206 - val_acc: 0.2275\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.3490 - acc: 0.2497 - val_loss: 2.4060 - val_acc: 0.2331\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.3147 - acc: 0.2577 - val_loss: 2.3227 - val_acc: 0.2776\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.2661 - acc: 0.2725 - val_loss: 2.2111 - val_acc: 0.2967\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 1s 54us/step - loss: 2.2498 - acc: 0.2773 - val_loss: 2.4207 - val_acc: 0.2131\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.2167 - acc: 0.2819 - val_loss: 2.2879 - val_acc: 0.2988\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.1785 - acc: 0.2933 - val_loss: 2.0625 - val_acc: 0.3402\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 1s 54us/step - loss: 2.1478 - acc: 0.3046 - val_loss: 2.2173 - val_acc: 0.2831\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.1154 - acc: 0.3168 - val_loss: 2.1770 - val_acc: 0.3001\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 1s 53us/step - loss: 2.0833 - acc: 0.3238 - val_loss: 2.4895 - val_acc: 0.2185\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.0614 - acc: 0.3311 - val_loss: 1.9997 - val_acc: 0.3637\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 2.0172 - acc: 0.3456 - val_loss: 2.1027 - val_acc: 0.2931\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 1s 52us/step - loss: 2.0047 - acc: 0.3522 - val_loss: 2.0757 - val_acc: 0.2970\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 1s 51us/step - loss: 1.9778 - acc: 0.3617 - val_loss: 1.9614 - val_acc: 0.3620\n",
      "[64, 16, 16, 128, 'sigmoid', 'tanh', 'tanh', 'sigmoid', <keras.optimizers.Adagrad object at 0x7feab4e8cb38>, 128, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 3s 132us/step - loss: 3.2193 - acc: 0.0444 - val_loss: 3.1845 - val_acc: 0.0438\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.2030 - acc: 0.0425 - val_loss: 3.1780 - val_acc: 0.0488\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1966 - acc: 0.0447 - val_loss: 3.1782 - val_acc: 0.0488\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.1942 - acc: 0.0415 - val_loss: 3.1774 - val_acc: 0.0418\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1898 - acc: 0.0427 - val_loss: 3.1774 - val_acc: 0.0418\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1893 - acc: 0.0412 - val_loss: 3.1772 - val_acc: 0.0488\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.1871 - acc: 0.0433 - val_loss: 3.1775 - val_acc: 0.0488\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.1866 - acc: 0.0421 - val_loss: 3.1767 - val_acc: 0.0426\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1876 - acc: 0.0437 - val_loss: 3.1769 - val_acc: 0.0484\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1854 - acc: 0.0443 - val_loss: 3.1764 - val_acc: 0.0418\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1836 - acc: 0.0428 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1839 - acc: 0.0436 - val_loss: 3.1764 - val_acc: 0.0448\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1849 - acc: 0.0430 - val_loss: 3.1766 - val_acc: 0.0488\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1844 - acc: 0.0424 - val_loss: 3.1767 - val_acc: 0.0488\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1838 - acc: 0.0420 - val_loss: 3.1765 - val_acc: 0.0418\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1818 - acc: 0.0451 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 3.1833 - acc: 0.0420 - val_loss: 3.1759 - val_acc: 0.0484\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1809 - acc: 0.0463 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1821 - acc: 0.0450 - val_loss: 3.1762 - val_acc: 0.0488\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1821 - acc: 0.0426 - val_loss: 3.1764 - val_acc: 0.0418\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1813 - acc: 0.0414 - val_loss: 3.1763 - val_acc: 0.0418\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1832 - acc: 0.0413 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1811 - acc: 0.0426 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1805 - acc: 0.0440 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1796 - acc: 0.0461 - val_loss: 3.1759 - val_acc: 0.0418\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1815 - acc: 0.0452 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1802 - acc: 0.0440 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 3.1822 - acc: 0.0415 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1802 - acc: 0.0462 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1804 - acc: 0.0438 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1806 - acc: 0.0425 - val_loss: 3.1763 - val_acc: 0.0418\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.1797 - acc: 0.0447 - val_loss: 3.1763 - val_acc: 0.0418\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.1805 - acc: 0.0431 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.1793 - acc: 0.0475 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.1789 - acc: 0.0447 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1799 - acc: 0.0436 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1797 - acc: 0.0458 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1790 - acc: 0.0452 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1793 - acc: 0.0471 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1802 - acc: 0.0439 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1797 - acc: 0.0414 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1786 - acc: 0.0451 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1786 - acc: 0.0438 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 3.1790 - acc: 0.0414 - val_loss: 3.1759 - val_acc: 0.0418\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.1790 - acc: 0.0440 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1798 - acc: 0.0435 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1789 - acc: 0.0431 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1791 - acc: 0.0442 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 3.1786 - acc: 0.0446 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 3.1789 - acc: 0.0436 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "[64, 16, 32, 128, 'sigmoid', 'tanh', 'relu', 'relu', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 64, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 4s 191us/step - loss: 3.1776 - acc: 0.0433 - val_loss: 3.1766 - val_acc: 0.0466\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1769 - acc: 0.0442 - val_loss: 3.1761 - val_acc: 0.0425\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 3s 149us/step - loss: 3.1765 - acc: 0.0450 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1756 - acc: 0.0487 - val_loss: 3.1754 - val_acc: 0.0446\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1756 - acc: 0.0446 - val_loss: 3.1751 - val_acc: 0.0418\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1753 - acc: 0.0452 - val_loss: 3.1755 - val_acc: 0.0418\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1751 - acc: 0.0479 - val_loss: 3.1748 - val_acc: 0.0438\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1747 - acc: 0.0470 - val_loss: 3.1754 - val_acc: 0.0484\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1745 - acc: 0.0477 - val_loss: 3.1750 - val_acc: 0.0469\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1740 - acc: 0.0510 - val_loss: 3.1745 - val_acc: 0.0501\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1734 - acc: 0.0521 - val_loss: 3.1725 - val_acc: 0.0492\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1725 - acc: 0.0544 - val_loss: 3.1720 - val_acc: 0.0964\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1712 - acc: 0.0577 - val_loss: 3.1718 - val_acc: 0.0490\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1692 - acc: 0.0624 - val_loss: 3.1704 - val_acc: 0.0696\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1676 - acc: 0.0648 - val_loss: 3.1669 - val_acc: 0.0849\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1644 - acc: 0.0708 - val_loss: 3.1628 - val_acc: 0.0726\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1597 - acc: 0.0730 - val_loss: 3.1574 - val_acc: 0.0969\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1518 - acc: 0.0783 - val_loss: 3.1478 - val_acc: 0.0874\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1418 - acc: 0.0827 - val_loss: 3.1340 - val_acc: 0.0934\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1247 - acc: 0.0821 - val_loss: 3.1229 - val_acc: 0.0904\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.0983 - acc: 0.0884 - val_loss: 3.0787 - val_acc: 0.1046\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.0650 - acc: 0.1020 - val_loss: 3.0390 - val_acc: 0.1199\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.0193 - acc: 0.1086 - val_loss: 3.1476 - val_acc: 0.0891\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 2.9595 - acc: 0.1299 - val_loss: 2.9042 - val_acc: 0.1462\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 2.8683 - acc: 0.1451 - val_loss: 2.8325 - val_acc: 0.1630\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 2.7478 - acc: 0.1712 - val_loss: 2.6372 - val_acc: 0.2223\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 2.6183 - acc: 0.1964 - val_loss: 2.5167 - val_acc: 0.2468\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 2.4779 - acc: 0.2220 - val_loss: 2.4221 - val_acc: 0.2339\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 2.3459 - acc: 0.2606 - val_loss: 2.3300 - val_acc: 0.2857\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 2.2432 - acc: 0.2799 - val_loss: 2.1209 - val_acc: 0.3510\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 2.1555 - acc: 0.3010 - val_loss: 2.1140 - val_acc: 0.3257\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 2.0744 - acc: 0.3290 - val_loss: 1.9957 - val_acc: 0.3551\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 2.0036 - acc: 0.3484 - val_loss: 1.9606 - val_acc: 0.3625\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 1.9350 - acc: 0.3727 - val_loss: 1.8793 - val_acc: 0.4050\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 1.8715 - acc: 0.3900 - val_loss: 1.7921 - val_acc: 0.4390\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 1.8230 - acc: 0.4046 - val_loss: 1.8717 - val_acc: 0.3852\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 1.7728 - acc: 0.4248 - val_loss: 1.6725 - val_acc: 0.4661\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 1.7195 - acc: 0.4388 - val_loss: 1.6386 - val_acc: 0.4844\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 1.6834 - acc: 0.4516 - val_loss: 1.6047 - val_acc: 0.4934\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 1.6398 - acc: 0.4637 - val_loss: 1.5218 - val_acc: 0.5256\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 1.5939 - acc: 0.4783 - val_loss: 1.5026 - val_acc: 0.5330\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 1.5536 - acc: 0.4907 - val_loss: 1.4528 - val_acc: 0.5384\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 1.5212 - acc: 0.5032 - val_loss: 1.4177 - val_acc: 0.5477\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 1.4800 - acc: 0.5124 - val_loss: 1.4359 - val_acc: 0.5355\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 1.4426 - acc: 0.5224 - val_loss: 1.4279 - val_acc: 0.5353\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 1.3990 - acc: 0.5391 - val_loss: 1.3418 - val_acc: 0.5700\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 1.3721 - acc: 0.5478 - val_loss: 1.2829 - val_acc: 0.5770\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 1.3379 - acc: 0.5576 - val_loss: 1.2385 - val_acc: 0.5969\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 1.3050 - acc: 0.5634 - val_loss: 1.2251 - val_acc: 0.6016\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 1.2722 - acc: 0.5763 - val_loss: 1.2845 - val_acc: 0.5680\n",
      "[16, 16, 16, 64, 'tanh', 'relu', 'tanh', 'tanh', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 64, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 3s 167us/step - loss: 3.1773 - acc: 0.0432 - val_loss: 3.1737 - val_acc: 0.0467\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 3.1723 - acc: 0.0487 - val_loss: 3.1702 - val_acc: 0.0552\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 3.1683 - acc: 0.0581 - val_loss: 3.1662 - val_acc: 0.0643\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 3.1629 - acc: 0.0638 - val_loss: 3.1595 - val_acc: 0.0711\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 3.1536 - acc: 0.0737 - val_loss: 3.1479 - val_acc: 0.0870\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 3.1365 - acc: 0.0927 - val_loss: 3.1235 - val_acc: 0.1141\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 3.0979 - acc: 0.1154 - val_loss: 3.0652 - val_acc: 0.1278\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 3.0104 - acc: 0.1173 - val_loss: 2.9437 - val_acc: 0.1156\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 2.8704 - acc: 0.1277 - val_loss: 2.7826 - val_acc: 0.1405\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 2.7123 - acc: 0.1634 - val_loss: 2.6213 - val_acc: 0.1912\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 2.5368 - acc: 0.2147 - val_loss: 2.4325 - val_acc: 0.2491\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 2.3669 - acc: 0.2514 - val_loss: 2.2626 - val_acc: 0.2922\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 2s 121us/step - loss: 2.2175 - acc: 0.2886 - val_loss: 2.1887 - val_acc: 0.2925\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 2.0986 - acc: 0.3249 - val_loss: 2.0059 - val_acc: 0.3720\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 2s 118us/step - loss: 1.9841 - acc: 0.3616 - val_loss: 1.9225 - val_acc: 0.4000\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 2s 116us/step - loss: 1.8872 - acc: 0.3965 - val_loss: 1.8118 - val_acc: 0.4394\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 1.7944 - acc: 0.4213 - val_loss: 1.7160 - val_acc: 0.4755\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 1.6942 - acc: 0.4644 - val_loss: 1.6145 - val_acc: 0.5162\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 1.6053 - acc: 0.4892 - val_loss: 1.5132 - val_acc: 0.5441\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 1.5137 - acc: 0.5212 - val_loss: 1.5582 - val_acc: 0.4884\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 1.4216 - acc: 0.5499 - val_loss: 1.3491 - val_acc: 0.5914\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 1.3316 - acc: 0.5807 - val_loss: 1.2630 - val_acc: 0.6110\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 2s 123us/step - loss: 1.2468 - acc: 0.6040 - val_loss: 1.1942 - val_acc: 0.6297\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 1.1746 - acc: 0.6258 - val_loss: 1.2958 - val_acc: 0.5687\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 2s 122us/step - loss: 1.1032 - acc: 0.6556 - val_loss: 1.0552 - val_acc: 0.6703\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 2s 121us/step - loss: 1.0535 - acc: 0.6675 - val_loss: 1.0774 - val_acc: 0.6408\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 2s 121us/step - loss: 0.9944 - acc: 0.6832 - val_loss: 0.9732 - val_acc: 0.6820\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 0.9387 - acc: 0.7074 - val_loss: 0.8907 - val_acc: 0.7342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 0.8893 - acc: 0.7258 - val_loss: 0.9264 - val_acc: 0.7131\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 0.8499 - acc: 0.7365 - val_loss: 0.8409 - val_acc: 0.7431\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 0.8092 - acc: 0.7512 - val_loss: 0.7931 - val_acc: 0.7531\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 2s 121us/step - loss: 0.7737 - acc: 0.7667 - val_loss: 0.7688 - val_acc: 0.7667\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 0.7351 - acc: 0.7809 - val_loss: 0.6899 - val_acc: 0.8008\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 2s 117us/step - loss: 0.7048 - acc: 0.7875 - val_loss: 0.6596 - val_acc: 0.8147\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 0.6749 - acc: 0.7986 - val_loss: 0.6895 - val_acc: 0.7959\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 0.6433 - acc: 0.8106 - val_loss: 0.6119 - val_acc: 0.8212\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 0.6187 - acc: 0.8205 - val_loss: 0.5835 - val_acc: 0.8292\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 2s 119us/step - loss: 0.5888 - acc: 0.8262 - val_loss: 0.6036 - val_acc: 0.8115\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 2s 121us/step - loss: 0.5642 - acc: 0.8379 - val_loss: 0.5476 - val_acc: 0.8435\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 2s 120us/step - loss: 0.5445 - acc: 0.8441 - val_loss: 0.6129 - val_acc: 0.8084\n",
      "[128, 32, 128, 64, 'tanh', 'tanh', 'relu', 'sigmoid', <keras.optimizers.Adagrad object at 0x7feab4e8cb38>, 64, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 5s 264us/step - loss: 2.2768 - acc: 0.3494 - val_loss: 1.3995 - val_acc: 0.6664\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 1.1456 - acc: 0.7168 - val_loss: 0.8545 - val_acc: 0.8238\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.7767 - acc: 0.8269 - val_loss: 0.6181 - val_acc: 0.8869\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.5778 - acc: 0.8860 - val_loss: 0.4641 - val_acc: 0.9229\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.4512 - acc: 0.9183 - val_loss: 0.3595 - val_acc: 0.9455\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.3623 - acc: 0.9409 - val_loss: 0.2839 - val_acc: 0.9625\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.2980 - acc: 0.9568 - val_loss: 0.2325 - val_acc: 0.9718\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.2496 - acc: 0.9686 - val_loss: 0.2015 - val_acc: 0.9763\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.2132 - acc: 0.9754 - val_loss: 0.1639 - val_acc: 0.9848\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.1820 - acc: 0.9817 - val_loss: 0.1387 - val_acc: 0.9856\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.1607 - acc: 0.9853 - val_loss: 0.1189 - val_acc: 0.9903\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.1407 - acc: 0.9884 - val_loss: 0.1024 - val_acc: 0.9933\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.1258 - acc: 0.9901 - val_loss: 0.0893 - val_acc: 0.9941\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.1118 - acc: 0.9931 - val_loss: 0.0793 - val_acc: 0.9956\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 4s 203us/step - loss: 0.1013 - acc: 0.9935 - val_loss: 0.0704 - val_acc: 0.9979\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0922 - acc: 0.9948 - val_loss: 0.0634 - val_acc: 0.9982\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.0843 - acc: 0.9962 - val_loss: 0.0584 - val_acc: 0.9983\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.0783 - acc: 0.9960 - val_loss: 0.0518 - val_acc: 0.9984\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.0719 - acc: 0.9967 - val_loss: 0.0470 - val_acc: 0.9984\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0677 - acc: 0.9969 - val_loss: 0.0494 - val_acc: 0.9982\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0629 - acc: 0.9976 - val_loss: 0.0403 - val_acc: 0.9987\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0588 - acc: 0.9980 - val_loss: 0.0373 - val_acc: 0.9984\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0567 - acc: 0.9980 - val_loss: 0.0341 - val_acc: 0.9992\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.0519 - acc: 0.9983 - val_loss: 0.0316 - val_acc: 0.9993\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0497 - acc: 0.9989 - val_loss: 0.0295 - val_acc: 0.9995\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0459 - acc: 0.9984 - val_loss: 0.0277 - val_acc: 0.9995\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.0435 - acc: 0.9991 - val_loss: 0.0260 - val_acc: 0.9996\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0418 - acc: 0.9988 - val_loss: 0.0250 - val_acc: 0.9998\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.0402 - acc: 0.9991 - val_loss: 0.0232 - val_acc: 0.9995\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0377 - acc: 0.9992 - val_loss: 0.0218 - val_acc: 0.9999\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 4s 201us/step - loss: 0.0364 - acc: 0.9994 - val_loss: 0.0208 - val_acc: 0.9998\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0355 - acc: 0.9993 - val_loss: 0.0197 - val_acc: 0.9999\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0331 - acc: 0.9993 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0321 - acc: 0.9994 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0317 - acc: 0.9993 - val_loss: 0.0170 - val_acc: 0.9999\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0301 - acc: 0.9993 - val_loss: 0.0163 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 4s 197us/step - loss: 0.0285 - acc: 0.9996 - val_loss: 0.0158 - val_acc: 0.9999\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0279 - acc: 0.9996 - val_loss: 0.0148 - val_acc: 0.9999\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.0266 - acc: 0.9997 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.0259 - acc: 0.9997 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0250 - acc: 0.9995 - val_loss: 0.0129 - val_acc: 0.9999\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0244 - acc: 0.9997 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 4s 202us/step - loss: 0.0242 - acc: 0.9997 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 4s 203us/step - loss: 0.0228 - acc: 0.9997 - val_loss: 0.0115 - val_acc: 0.9999\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0219 - acc: 0.9999 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 4s 203us/step - loss: 0.0220 - acc: 0.9998 - val_loss: 0.0110 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 0.0211 - acc: 0.9998 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.0204 - acc: 0.9997 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 4s 200us/step - loss: 0.0199 - acc: 0.9997 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 4s 199us/step - loss: 0.0196 - acc: 0.9997 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "[16, 64, 128, 128, 'tanh', 'relu', 'relu', 'relu', <keras.optimizers.Adagrad object at 0x7feab4e8cb38>, 64, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 4s 211us/step - loss: 1.7179 - acc: 0.4500 - val_loss: 0.8094 - val_acc: 0.7213\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 0.6528 - acc: 0.7810 - val_loss: 0.4837 - val_acc: 0.8496\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.4140 - acc: 0.8648 - val_loss: 0.3016 - val_acc: 0.9064\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.2811 - acc: 0.9123 - val_loss: 0.2029 - val_acc: 0.9371\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.2010 - acc: 0.9403 - val_loss: 0.1304 - val_acc: 0.9706\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 0.1543 - acc: 0.9562 - val_loss: 0.0859 - val_acc: 0.9817\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.1218 - acc: 0.9660 - val_loss: 0.0697 - val_acc: 0.9874\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.0957 - acc: 0.9758 - val_loss: 0.0490 - val_acc: 0.9942\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 0.0765 - acc: 0.9821 - val_loss: 0.0726 - val_acc: 0.9805\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.0656 - acc: 0.9851 - val_loss: 0.0297 - val_acc: 0.9981\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.0563 - acc: 0.9880 - val_loss: 0.0244 - val_acc: 0.9990\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.0463 - acc: 0.9911 - val_loss: 0.0213 - val_acc: 0.9990\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.0427 - acc: 0.9913 - val_loss: 0.0177 - val_acc: 0.9995\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0380 - acc: 0.9922 - val_loss: 0.0147 - val_acc: 0.9998\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.0329 - acc: 0.9945 - val_loss: 0.0133 - val_acc: 0.9996\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 0.0287 - acc: 0.9959 - val_loss: 0.0148 - val_acc: 0.9992\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 3s 168us/step - loss: 0.0269 - acc: 0.9958 - val_loss: 0.0095 - val_acc: 0.9999\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 3s 166us/step - loss: 0.0236 - acc: 0.9966 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 3s 168us/step - loss: 0.0217 - acc: 0.9966 - val_loss: 0.0076 - val_acc: 0.9999\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 3s 166us/step - loss: 0.0201 - acc: 0.9971 - val_loss: 0.0075 - val_acc: 0.9999\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 3s 168us/step - loss: 0.0192 - acc: 0.9970 - val_loss: 0.0062 - val_acc: 0.9999\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 3s 171us/step - loss: 0.0178 - acc: 0.9971 - val_loss: 0.0059 - val_acc: 0.9999\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 3s 170us/step - loss: 0.0174 - acc: 0.9965 - val_loss: 0.0053 - val_acc: 0.9999\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 3s 167us/step - loss: 0.0158 - acc: 0.9981 - val_loss: 0.0046 - val_acc: 0.9999\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 3s 164us/step - loss: 0.0148 - acc: 0.9977 - val_loss: 0.0045 - val_acc: 0.9999\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 3s 167us/step - loss: 0.0130 - acc: 0.9986 - val_loss: 0.0039 - val_acc: 0.9999\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 3s 168us/step - loss: 0.0128 - acc: 0.9982 - val_loss: 0.0037 - val_acc: 0.9999\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 3s 166us/step - loss: 0.0130 - acc: 0.9981 - val_loss: 0.0033 - val_acc: 0.9999\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 3s 165us/step - loss: 0.0107 - acc: 0.9989 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 3s 164us/step - loss: 0.0107 - acc: 0.9986 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 0.0110 - acc: 0.9986 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 0.0106 - acc: 0.9985 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 3s 167us/step - loss: 0.0093 - acc: 0.9991 - val_loss: 0.0025 - val_acc: 0.9999\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 3s 168us/step - loss: 0.0099 - acc: 0.9988 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 3s 166us/step - loss: 0.0082 - acc: 0.9990 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 3s 164us/step - loss: 0.0074 - acc: 0.9993 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 3s 165us/step - loss: 0.0077 - acc: 0.9991 - val_loss: 0.0021 - val_acc: 0.9999\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 3s 167us/step - loss: 0.0072 - acc: 0.9993 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 3s 169us/step - loss: 0.0073 - acc: 0.9993 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 3s 167us/step - loss: 0.0081 - acc: 0.9984 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "[16, 64, 64, 128, 'relu', 'tanh', 'relu', 'tanh', <keras.optimizers.Adamax object at 0x7feab4e8cf28>, 256, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 2.9411 - acc: 0.1375 - val_loss: 2.4534 - val_acc: 0.2825\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 1s 62us/step - loss: 2.0068 - acc: 0.4054 - val_loss: 1.5307 - val_acc: 0.5611\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 1.3274 - acc: 0.5917 - val_loss: 1.0664 - val_acc: 0.6813\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.9862 - acc: 0.6866 - val_loss: 0.8321 - val_acc: 0.7330\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.7797 - acc: 0.7577 - val_loss: 0.6454 - val_acc: 0.8167\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.6191 - acc: 0.8104 - val_loss: 0.5193 - val_acc: 0.8515\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.4979 - acc: 0.8556 - val_loss: 0.4194 - val_acc: 0.8833\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.4018 - acc: 0.8851 - val_loss: 0.3353 - val_acc: 0.9105\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.3265 - acc: 0.9104 - val_loss: 0.2604 - val_acc: 0.9336\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.2611 - acc: 0.9340 - val_loss: 0.2115 - val_acc: 0.9466\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 0.2118 - acc: 0.9512 - val_loss: 0.1705 - val_acc: 0.9656\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.1702 - acc: 0.9644 - val_loss: 0.1302 - val_acc: 0.9822\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.1387 - acc: 0.9739 - val_loss: 0.1128 - val_acc: 0.9837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.1149 - acc: 0.9799 - val_loss: 0.0891 - val_acc: 0.9902\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0922 - acc: 0.9860 - val_loss: 0.0713 - val_acc: 0.9920\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 0.0746 - acc: 0.9915 - val_loss: 0.0583 - val_acc: 0.9966\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0631 - acc: 0.9938 - val_loss: 0.0466 - val_acc: 0.9979\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0527 - acc: 0.9953 - val_loss: 0.0388 - val_acc: 0.9985\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0444 - acc: 0.9968 - val_loss: 0.0308 - val_acc: 0.9989\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0368 - acc: 0.9985 - val_loss: 0.0251 - val_acc: 0.9990\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0311 - acc: 0.9984 - val_loss: 0.0226 - val_acc: 0.9990\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0272 - acc: 0.9987 - val_loss: 0.0193 - val_acc: 0.9992\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0235 - acc: 0.9991 - val_loss: 0.0159 - val_acc: 0.9996\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0206 - acc: 0.9990 - val_loss: 0.0133 - val_acc: 0.9996\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0179 - acc: 0.9994 - val_loss: 0.0113 - val_acc: 0.9999\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0148 - acc: 0.9997 - val_loss: 0.0121 - val_acc: 0.9994\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0141 - acc: 0.9998 - val_loss: 0.0085 - val_acc: 0.9996\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0112 - acc: 0.9998 - val_loss: 0.0078 - val_acc: 0.9998\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0109 - acc: 0.9995 - val_loss: 0.0080 - val_acc: 0.9996\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0093 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9999\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0082 - acc: 0.9999 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0073 - acc: 0.9999 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0064 - acc: 0.9999 - val_loss: 0.0051 - val_acc: 0.9998\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 0.0059 - acc: 0.9999 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9999\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0046 - acc: 0.9998 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "[16, 16, 32, 32, 'tanh', 'tanh', 'tanh', 'relu', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 256, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 2s 107us/step - loss: 3.1813 - acc: 0.0451 - val_loss: 3.1782 - val_acc: 0.0371\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.1764 - acc: 0.0419 - val_loss: 3.1753 - val_acc: 0.0528\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.1738 - acc: 0.0461 - val_loss: 3.1735 - val_acc: 0.0499\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1720 - acc: 0.0488 - val_loss: 3.1719 - val_acc: 0.0558\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 1s 47us/step - loss: 3.1707 - acc: 0.0503 - val_loss: 3.1701 - val_acc: 0.0646\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.1690 - acc: 0.0529 - val_loss: 3.1683 - val_acc: 0.0596\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1672 - acc: 0.0528 - val_loss: 3.1664 - val_acc: 0.0523\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1652 - acc: 0.0510 - val_loss: 3.1643 - val_acc: 0.0652\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1630 - acc: 0.0571 - val_loss: 3.1617 - val_acc: 0.0764\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.1606 - acc: 0.0590 - val_loss: 3.1598 - val_acc: 0.0577\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.1582 - acc: 0.0589 - val_loss: 3.1569 - val_acc: 0.0789\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.1557 - acc: 0.0653 - val_loss: 3.1539 - val_acc: 0.0648\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1523 - acc: 0.0647 - val_loss: 3.1508 - val_acc: 0.0707\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1496 - acc: 0.0700 - val_loss: 3.1477 - val_acc: 0.0737\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1459 - acc: 0.0696 - val_loss: 3.1439 - val_acc: 0.0817\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.1421 - acc: 0.0743 - val_loss: 3.1395 - val_acc: 0.0897\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 1s 47us/step - loss: 3.1384 - acc: 0.0767 - val_loss: 3.1355 - val_acc: 0.0889\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1341 - acc: 0.0780 - val_loss: 3.1307 - val_acc: 0.0965\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1279 - acc: 0.0833 - val_loss: 3.1241 - val_acc: 0.0989\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1222 - acc: 0.0885 - val_loss: 3.1183 - val_acc: 0.0960\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.1165 - acc: 0.0904 - val_loss: 3.1116 - val_acc: 0.1004\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.1079 - acc: 0.0941 - val_loss: 3.1029 - val_acc: 0.1128\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.0995 - acc: 0.1015 - val_loss: 3.0939 - val_acc: 0.1099\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.0918 - acc: 0.1038 - val_loss: 3.0837 - val_acc: 0.1189\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.0819 - acc: 0.1040 - val_loss: 3.0717 - val_acc: 0.1244\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.0695 - acc: 0.1124 - val_loss: 3.0588 - val_acc: 0.1327\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.0559 - acc: 0.1143 - val_loss: 3.0435 - val_acc: 0.1360\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 3.0405 - acc: 0.1215 - val_loss: 3.0261 - val_acc: 0.1383\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.0242 - acc: 0.1249 - val_loss: 3.0080 - val_acc: 0.1344\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 3.0057 - acc: 0.1273 - val_loss: 2.9853 - val_acc: 0.1477\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 2.9814 - acc: 0.1338 - val_loss: 2.9604 - val_acc: 0.1509\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 2.9585 - acc: 0.1324 - val_loss: 2.9333 - val_acc: 0.1516\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 2.9306 - acc: 0.1346 - val_loss: 2.9034 - val_acc: 0.1583\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 2.9021 - acc: 0.1446 - val_loss: 2.8711 - val_acc: 0.1598\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 2.8736 - acc: 0.1495 - val_loss: 2.8390 - val_acc: 0.1748\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 2.8436 - acc: 0.1513 - val_loss: 2.8011 - val_acc: 0.1803\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 2.8073 - acc: 0.1613 - val_loss: 2.7645 - val_acc: 0.1986\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 2.7700 - acc: 0.1711 - val_loss: 2.7265 - val_acc: 0.2074\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 1s 45us/step - loss: 2.7363 - acc: 0.1811 - val_loss: 2.6879 - val_acc: 0.2191\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 1s 46us/step - loss: 2.7022 - acc: 0.1929 - val_loss: 2.6487 - val_acc: 0.2310\n",
      "[32, 32, 64, 16, 'relu', 'sigmoid', 'relu', 'tanh', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 256, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1843 - acc: 0.0409 - val_loss: 3.1777 - val_acc: 0.0384\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1780 - acc: 0.0416 - val_loss: 3.1766 - val_acc: 0.0447\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1775 - acc: 0.0432 - val_loss: 3.1764 - val_acc: 0.0402\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1772 - acc: 0.0431 - val_loss: 3.1772 - val_acc: 0.0436\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1770 - acc: 0.0443 - val_loss: 3.1770 - val_acc: 0.0429\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1768 - acc: 0.0441 - val_loss: 3.1773 - val_acc: 0.0425\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1767 - acc: 0.0431 - val_loss: 3.1756 - val_acc: 0.0425\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1767 - acc: 0.0444 - val_loss: 3.1757 - val_acc: 0.0429\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 3.1765 - acc: 0.0434 - val_loss: 3.1765 - val_acc: 0.0454\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1761 - acc: 0.0433 - val_loss: 3.1754 - val_acc: 0.0425\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 1s 55us/step - loss: 3.1762 - acc: 0.0436 - val_loss: 3.1756 - val_acc: 0.0425\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1762 - acc: 0.0414 - val_loss: 3.1756 - val_acc: 0.0488\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1757 - acc: 0.0436 - val_loss: 3.1757 - val_acc: 0.0425\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1758 - acc: 0.0457 - val_loss: 3.1755 - val_acc: 0.0488\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1757 - acc: 0.0479 - val_loss: 3.1757 - val_acc: 0.0418\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1753 - acc: 0.0453 - val_loss: 3.1758 - val_acc: 0.0458\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1754 - acc: 0.0471 - val_loss: 3.1751 - val_acc: 0.0448\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1756 - acc: 0.0476 - val_loss: 3.1766 - val_acc: 0.0715\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1753 - acc: 0.0461 - val_loss: 3.1755 - val_acc: 0.0675\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 3.1752 - acc: 0.0458 - val_loss: 3.1751 - val_acc: 0.0648\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1753 - acc: 0.0491 - val_loss: 3.1749 - val_acc: 0.0441\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1754 - acc: 0.0479 - val_loss: 3.1747 - val_acc: 0.0484\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1749 - acc: 0.0490 - val_loss: 3.1749 - val_acc: 0.0469\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1749 - acc: 0.0473 - val_loss: 3.1748 - val_acc: 0.0453\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1751 - acc: 0.0489 - val_loss: 3.1746 - val_acc: 0.0504\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 3.1747 - acc: 0.0480 - val_loss: 3.1747 - val_acc: 0.0409\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 3.1747 - acc: 0.0499 - val_loss: 3.1742 - val_acc: 0.0488\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1746 - acc: 0.0509 - val_loss: 3.1746 - val_acc: 0.0538\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1743 - acc: 0.0482 - val_loss: 3.1747 - val_acc: 0.0426\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1746 - acc: 0.0508 - val_loss: 3.1744 - val_acc: 0.0488\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1744 - acc: 0.0490 - val_loss: 3.1742 - val_acc: 0.0518\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1744 - acc: 0.0498 - val_loss: 3.1750 - val_acc: 0.0459\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1743 - acc: 0.0522 - val_loss: 3.1740 - val_acc: 0.0488\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1742 - acc: 0.0496 - val_loss: 3.1749 - val_acc: 0.0371\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1741 - acc: 0.0465 - val_loss: 3.1740 - val_acc: 0.0635\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1740 - acc: 0.0510 - val_loss: 3.1737 - val_acc: 0.0520\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1740 - acc: 0.0503 - val_loss: 3.1735 - val_acc: 0.0484\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1740 - acc: 0.0507 - val_loss: 3.1743 - val_acc: 0.0427\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 1s 55us/step - loss: 3.1736 - acc: 0.0531 - val_loss: 3.1734 - val_acc: 0.0488\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1736 - acc: 0.0527 - val_loss: 3.1738 - val_acc: 0.0465\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 1s 55us/step - loss: 3.1734 - acc: 0.0522 - val_loss: 3.1738 - val_acc: 0.0657\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1735 - acc: 0.0546 - val_loss: 3.1735 - val_acc: 0.0493\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1731 - acc: 0.0496 - val_loss: 3.1732 - val_acc: 0.0640\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1731 - acc: 0.0556 - val_loss: 3.1732 - val_acc: 0.0657\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1730 - acc: 0.0538 - val_loss: 3.1727 - val_acc: 0.0529\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1726 - acc: 0.0584 - val_loss: 3.1729 - val_acc: 0.0597\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1727 - acc: 0.0503 - val_loss: 3.1728 - val_acc: 0.0532\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 1s 57us/step - loss: 3.1724 - acc: 0.0554 - val_loss: 3.1727 - val_acc: 0.0484\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 1s 56us/step - loss: 3.1725 - acc: 0.0539 - val_loss: 3.1725 - val_acc: 0.0605\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19218/19218 [==============================] - 1s 55us/step - loss: 3.1721 - acc: 0.0540 - val_loss: 3.1727 - val_acc: 0.0511\n",
      "[128, 128, 32, 16, 'tanh', 'tanh', 'sigmoid', 'relu', <keras.optimizers.Adagrad object at 0x7feab4e8cb38>, 256, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 5s 243us/step - loss: 3.1805 - acc: 0.0409 - val_loss: 3.1769 - val_acc: 0.0488\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1766 - acc: 0.0452 - val_loss: 3.1765 - val_acc: 0.0488\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1762 - acc: 0.0464 - val_loss: 3.1763 - val_acc: 0.0488\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1760 - acc: 0.0464 - val_loss: 3.1762 - val_acc: 0.0488\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1759 - acc: 0.0455 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1758 - acc: 0.0443 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1757 - acc: 0.0457 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1757 - acc: 0.0444 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1757 - acc: 0.0453 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 3.1756 - acc: 0.0457 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1755 - acc: 0.0452 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 3.1755 - acc: 0.0464 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1755 - acc: 0.0455 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1755 - acc: 0.0466 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1755 - acc: 0.0461 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1755 - acc: 0.0453 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1755 - acc: 0.0456 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1755 - acc: 0.0431 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1755 - acc: 0.0455 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1755 - acc: 0.0449 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1755 - acc: 0.0431 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1755 - acc: 0.0466 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1754 - acc: 0.0465 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.1754 - acc: 0.0464 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "[32, 64, 16, 128, 'tanh', 'tanh', 'sigmoid', 'relu', <keras.optimizers.Adamax object at 0x7feab4e8cf28>, 256, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1581 - acc: 0.0631 - val_loss: 3.0743 - val_acc: 0.1095\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 2.8916 - acc: 0.1448 - val_loss: 2.6623 - val_acc: 0.2041\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 1s 66us/step - loss: 2.4934 - acc: 0.2377 - val_loss: 2.2674 - val_acc: 0.3258\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 1s 67us/step - loss: 2.1517 - acc: 0.3225 - val_loss: 1.9439 - val_acc: 0.4089\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 1s 66us/step - loss: 1.8740 - acc: 0.4065 - val_loss: 1.7018 - val_acc: 0.4906\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 1.6520 - acc: 0.4738 - val_loss: 1.5059 - val_acc: 0.5373\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 1.4881 - acc: 0.5165 - val_loss: 1.3444 - val_acc: 0.5972\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 1.3587 - acc: 0.5655 - val_loss: 1.2212 - val_acc: 0.6419\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 1.2430 - acc: 0.6004 - val_loss: 1.1674 - val_acc: 0.6434\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 1.1324 - acc: 0.6439 - val_loss: 1.0069 - val_acc: 0.7073\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 1.0271 - acc: 0.6766 - val_loss: 0.9069 - val_acc: 0.7499\n",
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.9424 - acc: 0.7079 - val_loss: 0.8156 - val_acc: 0.7811\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.8544 - acc: 0.7392 - val_loss: 0.7739 - val_acc: 0.7925\n",
      "Epoch 14/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 0.7785 - acc: 0.7633 - val_loss: 0.6828 - val_acc: 0.8157\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 1s 63us/step - loss: 0.7097 - acc: 0.7856 - val_loss: 0.6183 - val_acc: 0.8469\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 1s 63us/step - loss: 0.6475 - acc: 0.8098 - val_loss: 0.5780 - val_acc: 0.8468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 1s 63us/step - loss: 0.5982 - acc: 0.8235 - val_loss: 0.5085 - val_acc: 0.8729\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 1s 63us/step - loss: 0.5507 - acc: 0.8376 - val_loss: 0.4914 - val_acc: 0.8793\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.5122 - acc: 0.8503 - val_loss: 0.4575 - val_acc: 0.8836\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 0.4741 - acc: 0.8623 - val_loss: 0.3997 - val_acc: 0.8970\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.4348 - acc: 0.8735 - val_loss: 0.3728 - val_acc: 0.9053\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.4016 - acc: 0.8852 - val_loss: 0.3503 - val_acc: 0.9083\n",
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 1s 66us/step - loss: 0.3769 - acc: 0.8930 - val_loss: 0.3086 - val_acc: 0.9276\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 1s 66us/step - loss: 0.3482 - acc: 0.9038 - val_loss: 0.3000 - val_acc: 0.9267\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.3211 - acc: 0.9107 - val_loss: 0.2765 - val_acc: 0.9325\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.2988 - acc: 0.9168 - val_loss: 0.2623 - val_acc: 0.9378\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.2809 - acc: 0.9227 - val_loss: 0.2242 - val_acc: 0.9480\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 1s 64us/step - loss: 0.2535 - acc: 0.9347 - val_loss: 0.2012 - val_acc: 0.9561\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 0.2300 - acc: 0.9408 - val_loss: 0.1769 - val_acc: 0.9654\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 1s 65us/step - loss: 0.2121 - acc: 0.9456 - val_loss: 0.1716 - val_acc: 0.9627\n",
      "[32, 32, 32, 64, 'relu', 'tanh', 'relu', 'sigmoid', <keras.optimizers.Adamax object at 0x7feab4e8cf28>, 128, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 3s 176us/step - loss: 3.2212 - acc: 0.0476 - val_loss: 3.1540 - val_acc: 0.1074\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 3.0203 - acc: 0.1078 - val_loss: 2.7671 - val_acc: 0.1898\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 2.5419 - acc: 0.2330 - val_loss: 2.2238 - val_acc: 0.3755\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 2s 87us/step - loss: 2.0571 - acc: 0.3729 - val_loss: 1.7912 - val_acc: 0.5194\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 1.6889 - acc: 0.4953 - val_loss: 1.4524 - val_acc: 0.6166\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 2s 87us/step - loss: 1.3934 - acc: 0.5871 - val_loss: 1.1915 - val_acc: 0.6861\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 1.1510 - acc: 0.6692 - val_loss: 0.9863 - val_acc: 0.7401\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 2s 88us/step - loss: 0.9723 - acc: 0.7195 - val_loss: 0.8185 - val_acc: 0.7930\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 0.8211 - acc: 0.7711 - val_loss: 0.6915 - val_acc: 0.8163\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 2s 88us/step - loss: 0.7083 - acc: 0.8046 - val_loss: 0.5883 - val_acc: 0.8513\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 2s 88us/step - loss: 0.6085 - acc: 0.8344 - val_loss: 0.4978 - val_acc: 0.8847\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 0.5245 - acc: 0.8643 - val_loss: 0.4217 - val_acc: 0.9012\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 2s 88us/step - loss: 0.4580 - acc: 0.8817 - val_loss: 0.3746 - val_acc: 0.9114\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 0.4002 - acc: 0.8974 - val_loss: 0.3100 - val_acc: 0.9381\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 0.3483 - acc: 0.9165 - val_loss: 0.2754 - val_acc: 0.9389\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 2s 88us/step - loss: 0.3041 - acc: 0.9295 - val_loss: 0.2287 - val_acc: 0.9542\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 0.2662 - acc: 0.9411 - val_loss: 0.2057 - val_acc: 0.9632\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 2s 88us/step - loss: 0.2366 - acc: 0.9480 - val_loss: 0.1678 - val_acc: 0.9733\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 2s 89us/step - loss: 0.2070 - acc: 0.9559 - val_loss: 0.1442 - val_acc: 0.9778\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 0.1808 - acc: 0.9660 - val_loss: 0.1226 - val_acc: 0.9848\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.1600 - acc: 0.9693 - val_loss: 0.1089 - val_acc: 0.9860\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.1434 - acc: 0.9732 - val_loss: 0.0921 - val_acc: 0.9898\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.1264 - acc: 0.9777 - val_loss: 0.0785 - val_acc: 0.9914\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.1143 - acc: 0.9800 - val_loss: 0.0724 - val_acc: 0.9917\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.1014 - acc: 0.9829 - val_loss: 0.0660 - val_acc: 0.9937\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0881 - acc: 0.9869 - val_loss: 0.0482 - val_acc: 0.9965\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0776 - acc: 0.9888 - val_loss: 0.0416 - val_acc: 0.9975\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.0700 - acc: 0.9900 - val_loss: 0.0371 - val_acc: 0.9971\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0629 - acc: 0.9917 - val_loss: 0.0316 - val_acc: 0.9982\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 0.0564 - acc: 0.9933 - val_loss: 0.0258 - val_acc: 0.9985\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 2s 90us/step - loss: 0.0513 - acc: 0.9938 - val_loss: 0.0239 - val_acc: 0.9985\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0472 - acc: 0.9945 - val_loss: 0.0196 - val_acc: 0.9989\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.0419 - acc: 0.9954 - val_loss: 0.0177 - val_acc: 0.9995\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.0378 - acc: 0.9958 - val_loss: 0.0161 - val_acc: 0.9994\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 2s 94us/step - loss: 0.0346 - acc: 0.9964 - val_loss: 0.0139 - val_acc: 0.9998\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.0307 - acc: 0.9973 - val_loss: 0.0132 - val_acc: 0.9989\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0295 - acc: 0.9969 - val_loss: 0.0107 - val_acc: 0.9995\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.0277 - acc: 0.9973 - val_loss: 0.0089 - val_acc: 0.9999\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0255 - acc: 0.9978 - val_loss: 0.0101 - val_acc: 0.9995\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0235 - acc: 0.9974 - val_loss: 0.0079 - val_acc: 0.9999\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.0222 - acc: 0.9980 - val_loss: 0.0076 - val_acc: 0.9998\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0214 - acc: 0.9977 - val_loss: 0.0062 - val_acc: 0.9999\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.0188 - acc: 0.9983 - val_loss: 0.0066 - val_acc: 0.9999\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.0181 - acc: 0.9986 - val_loss: 0.0049 - val_acc: 0.9999\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.0161 - acc: 0.9988 - val_loss: 0.0076 - val_acc: 0.9996\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0164 - acc: 0.9988 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0142 - acc: 0.9990 - val_loss: 0.0043 - val_acc: 0.9998\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 2s 93us/step - loss: 0.0141 - acc: 0.9989 - val_loss: 0.0045 - val_acc: 0.9996\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 2s 92us/step - loss: 0.0137 - acc: 0.9988 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 2s 91us/step - loss: 0.0125 - acc: 0.9992 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "[32, 32, 32, 64, 'relu', 'sigmoid', 'tanh', 'relu', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 64, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 5s 236us/step - loss: 3.1847 - acc: 0.0426 - val_loss: 3.1786 - val_acc: 0.0425\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 3.1779 - acc: 0.0444 - val_loss: 3.1772 - val_acc: 0.0418\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1770 - acc: 0.0474 - val_loss: 3.1778 - val_acc: 0.0418\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1763 - acc: 0.0438 - val_loss: 3.1768 - val_acc: 0.0427\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1762 - acc: 0.0453 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 3.1760 - acc: 0.0455 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1757 - acc: 0.0459 - val_loss: 3.1762 - val_acc: 0.0488\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 3.1756 - acc: 0.0462 - val_loss: 3.1765 - val_acc: 0.0418\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1755 - acc: 0.0482 - val_loss: 3.1752 - val_acc: 0.0664\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1754 - acc: 0.0476 - val_loss: 3.1753 - val_acc: 0.0488\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1750 - acc: 0.0481 - val_loss: 3.1751 - val_acc: 0.0548\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1749 - acc: 0.0503 - val_loss: 3.1748 - val_acc: 0.0418\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 3.1745 - acc: 0.0499 - val_loss: 3.1748 - val_acc: 0.0637\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1746 - acc: 0.0484 - val_loss: 3.1748 - val_acc: 0.0488\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1743 - acc: 0.0507 - val_loss: 3.1739 - val_acc: 0.0515\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1742 - acc: 0.0508 - val_loss: 3.1736 - val_acc: 0.0751\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 3.1735 - acc: 0.0504 - val_loss: 3.1741 - val_acc: 0.0488\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 3s 139us/step - loss: 3.1730 - acc: 0.0542 - val_loss: 3.1728 - val_acc: 0.0801\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 3.1725 - acc: 0.0576 - val_loss: 3.1726 - val_acc: 0.0558\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 3.1715 - acc: 0.0533 - val_loss: 3.1708 - val_acc: 0.0523\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1704 - acc: 0.0612 - val_loss: 3.1703 - val_acc: 0.0728\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 3.1678 - acc: 0.0606 - val_loss: 3.1680 - val_acc: 0.0512\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1650 - acc: 0.0664 - val_loss: 3.1627 - val_acc: 0.0815\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.1616 - acc: 0.0726 - val_loss: 3.1575 - val_acc: 0.0782\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 3.1551 - acc: 0.0728 - val_loss: 3.1514 - val_acc: 0.0850\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1477 - acc: 0.0788 - val_loss: 3.1418 - val_acc: 0.0856\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1372 - acc: 0.0816 - val_loss: 3.1281 - val_acc: 0.0877\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1226 - acc: 0.0864 - val_loss: 3.1109 - val_acc: 0.1030\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 3.1032 - acc: 0.0865 - val_loss: 3.0854 - val_acc: 0.0996\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.0762 - acc: 0.0907 - val_loss: 3.0636 - val_acc: 0.0989\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 3.0433 - acc: 0.0977 - val_loss: 3.0182 - val_acc: 0.1025\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 3.0052 - acc: 0.1009 - val_loss: 2.9714 - val_acc: 0.1283\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 2.9606 - acc: 0.1098 - val_loss: 2.9194 - val_acc: 0.1374\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 2.9123 - acc: 0.1183 - val_loss: 2.8663 - val_acc: 0.1520\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 2.8572 - acc: 0.1334 - val_loss: 2.8185 - val_acc: 0.1491\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 2.8062 - acc: 0.1395 - val_loss: 2.7518 - val_acc: 0.1617\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 2.7518 - acc: 0.1541 - val_loss: 2.6914 - val_acc: 0.1689\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 3s 140us/step - loss: 2.7006 - acc: 0.1680 - val_loss: 2.6442 - val_acc: 0.1961\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 2.6387 - acc: 0.1811 - val_loss: 2.5662 - val_acc: 0.2118\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 3s 141us/step - loss: 2.5701 - acc: 0.1994 - val_loss: 2.4770 - val_acc: 0.2364\n",
      "[128, 128, 32, 128, 'sigmoid', 'sigmoid', 'tanh', 'sigmoid', <keras.optimizers.Adagrad object at 0x7feab4e8cb38>, 64, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 7s 345us/step - loss: 3.2111 - acc: 0.0426 - val_loss: 3.1777 - val_acc: 0.0465\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 5s 243us/step - loss: 3.1933 - acc: 0.0423 - val_loss: 3.1774 - val_acc: 0.0484\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1871 - acc: 0.0448 - val_loss: 3.1773 - val_acc: 0.0446\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 5s 243us/step - loss: 3.1855 - acc: 0.0408 - val_loss: 3.1763 - val_acc: 0.0488\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 3.1839 - acc: 0.0439 - val_loss: 3.1767 - val_acc: 0.0418\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 5s 239us/step - loss: 3.1811 - acc: 0.0439 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 5s 240us/step - loss: 3.1814 - acc: 0.0439 - val_loss: 3.1767 - val_acc: 0.0418\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 5s 244us/step - loss: 3.1805 - acc: 0.0442 - val_loss: 3.1763 - val_acc: 0.0488\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1816 - acc: 0.0430 - val_loss: 3.1760 - val_acc: 0.0484\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1809 - acc: 0.0436 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 5s 243us/step - loss: 3.1800 - acc: 0.0418 - val_loss: 3.1763 - val_acc: 0.0418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 3.1787 - acc: 0.0458 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 5s 240us/step - loss: 3.1781 - acc: 0.0431 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 14/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1794 - acc: 0.0436 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 3.1784 - acc: 0.0434 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1784 - acc: 0.0433 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 3.1781 - acc: 0.0460 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1782 - acc: 0.0416 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 3.1770 - acc: 0.0456 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 3.1779 - acc: 0.0452 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 3.1783 - acc: 0.0459 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 5s 240us/step - loss: 3.1777 - acc: 0.0437 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1776 - acc: 0.0439 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1772 - acc: 0.0447 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 5s 243us/step - loss: 3.1789 - acc: 0.0419 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 3.1771 - acc: 0.0450 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1776 - acc: 0.0415 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 5s 240us/step - loss: 3.1764 - acc: 0.0450 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 5s 239us/step - loss: 3.1767 - acc: 0.0464 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 5s 242us/step - loss: 3.1780 - acc: 0.0419 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "[16, 128, 16, 16, 'tanh', 'tanh', 'relu', 'relu', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 64, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 5s 269us/step - loss: 3.1752 - acc: 0.0468 - val_loss: 3.1726 - val_acc: 0.0500\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1698 - acc: 0.0570 - val_loss: 3.1668 - val_acc: 0.0698\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 3.1637 - acc: 0.0609 - val_loss: 3.1598 - val_acc: 0.0659\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 3.1550 - acc: 0.0676 - val_loss: 3.1493 - val_acc: 0.0671\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 3.1431 - acc: 0.0686 - val_loss: 3.1328 - val_acc: 0.0743\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 3.1204 - acc: 0.0768 - val_loss: 3.1081 - val_acc: 0.0693\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 3.0836 - acc: 0.0843 - val_loss: 3.0555 - val_acc: 0.0663\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 3.0242 - acc: 0.0908 - val_loss: 2.9686 - val_acc: 0.0957\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 2.9350 - acc: 0.1081 - val_loss: 2.8543 - val_acc: 0.1248\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 2.8278 - acc: 0.1216 - val_loss: 2.7252 - val_acc: 0.1221\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 2.7191 - acc: 0.1401 - val_loss: 2.5888 - val_acc: 0.1806\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 2.6048 - acc: 0.1750 - val_loss: 2.4562 - val_acc: 0.2210\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 2.5024 - acc: 0.2017 - val_loss: 2.3270 - val_acc: 0.2938\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 2.3909 - acc: 0.2385 - val_loss: 2.1961 - val_acc: 0.3280\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 2.2628 - acc: 0.2708 - val_loss: 2.0742 - val_acc: 0.3704\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 2.1489 - acc: 0.2959 - val_loss: 1.9241 - val_acc: 0.3938\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 2.0312 - acc: 0.3336 - val_loss: 1.8242 - val_acc: 0.4364\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 1.9329 - acc: 0.3579 - val_loss: 1.6964 - val_acc: 0.4628\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 1.8287 - acc: 0.3882 - val_loss: 1.5797 - val_acc: 0.5014\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 1.7399 - acc: 0.4097 - val_loss: 1.4927 - val_acc: 0.5240\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 1.6641 - acc: 0.4329 - val_loss: 1.4164 - val_acc: 0.5515\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 1.5908 - acc: 0.4502 - val_loss: 1.3820 - val_acc: 0.5345\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 1.5153 - acc: 0.4763 - val_loss: 1.2969 - val_acc: 0.5784\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 1.4555 - acc: 0.4897 - val_loss: 1.1806 - val_acc: 0.6349\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 1.3855 - acc: 0.5167 - val_loss: 1.1034 - val_acc: 0.6603\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 1.3148 - acc: 0.5379 - val_loss: 1.0577 - val_acc: 0.6625\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 1.2522 - acc: 0.5630 - val_loss: 0.9721 - val_acc: 0.7009\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 1.1968 - acc: 0.5792 - val_loss: 0.9118 - val_acc: 0.7217\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 1.1353 - acc: 0.5998 - val_loss: 0.8835 - val_acc: 0.7285\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 1.0876 - acc: 0.6167 - val_loss: 0.8278 - val_acc: 0.7417\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 1.0379 - acc: 0.6324 - val_loss: 0.7513 - val_acc: 0.7755\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 3s 162us/step - loss: 0.9968 - acc: 0.6454 - val_loss: 0.7246 - val_acc: 0.7793\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 0.9526 - acc: 0.6625 - val_loss: 0.7966 - val_acc: 0.7393\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 0.9196 - acc: 0.6717 - val_loss: 0.6297 - val_acc: 0.8187\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.8769 - acc: 0.6878 - val_loss: 0.5878 - val_acc: 0.8302\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 0.8556 - acc: 0.6985 - val_loss: 0.5632 - val_acc: 0.8400\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 0.8040 - acc: 0.7142 - val_loss: 0.5439 - val_acc: 0.8343\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 0.7875 - acc: 0.7206 - val_loss: 0.5182 - val_acc: 0.8498\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.7599 - acc: 0.7308 - val_loss: 0.4912 - val_acc: 0.8558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 3s 164us/step - loss: 0.7344 - acc: 0.7400 - val_loss: 0.4526 - val_acc: 0.8814\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 3s 169us/step - loss: 0.7022 - acc: 0.7521 - val_loss: 0.4213 - val_acc: 0.8887\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.6772 - acc: 0.7609 - val_loss: 0.4334 - val_acc: 0.8773\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 0.6456 - acc: 0.7747 - val_loss: 0.4020 - val_acc: 0.8872\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.6284 - acc: 0.7779 - val_loss: 0.3493 - val_acc: 0.9102\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 0.6142 - acc: 0.7832 - val_loss: 0.3309 - val_acc: 0.9147\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 3s 162us/step - loss: 0.5850 - acc: 0.7975 - val_loss: 0.3196 - val_acc: 0.9193\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.5599 - acc: 0.8064 - val_loss: 0.2816 - val_acc: 0.9342\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.5471 - acc: 0.8109 - val_loss: 0.2749 - val_acc: 0.9359\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 3s 162us/step - loss: 0.5292 - acc: 0.8180 - val_loss: 0.2615 - val_acc: 0.9418\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.5081 - acc: 0.8258 - val_loss: 0.2313 - val_acc: 0.9534\n",
      "[32, 16, 128, 32, 'relu', 'sigmoid', 'tanh', 'relu', <keras.optimizers.Adamax object at 0x7feab4e8cf28>, 256, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 3s 181us/step - loss: 3.1795 - acc: 0.0441 - val_loss: 3.1774 - val_acc: 0.0418\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 1s 61us/step - loss: 3.1771 - acc: 0.0441 - val_loss: 3.1769 - val_acc: 0.0488\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1766 - acc: 0.0446 - val_loss: 3.1767 - val_acc: 0.0488\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1764 - acc: 0.0461 - val_loss: 3.1765 - val_acc: 0.0418\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1762 - acc: 0.0467 - val_loss: 3.1764 - val_acc: 0.0418\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1760 - acc: 0.0447 - val_loss: 3.1763 - val_acc: 0.0418\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 3.1759 - acc: 0.0467 - val_loss: 3.1763 - val_acc: 0.0418\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1758 - acc: 0.0467 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1758 - acc: 0.0467 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1757 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1757 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1756 - acc: 0.0454 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1756 - acc: 0.0464 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1756 - acc: 0.0464 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 1s 61us/step - loss: 3.1755 - acc: 0.0459 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0458 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0464 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0460 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0473 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0448 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 1s 62us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 1s 58us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 1s 63us/step - loss: 3.1755 - acc: 0.0452 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 1s 61us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 1s 59us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 1s 60us/step - loss: 3.1755 - acc: 0.0463 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "[32, 16, 32, 16, 'sigmoid', 'relu', 'relu', 'sigmoid', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 128, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 4s 198us/step - loss: 3.2537 - acc: 0.0393 - val_loss: 3.2101 - val_acc: 0.0448\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 2s 81us/step - loss: 3.2203 - acc: 0.0416 - val_loss: 3.1928 - val_acc: 0.0448\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 2s 83us/step - loss: 3.2034 - acc: 0.0409 - val_loss: 3.1850 - val_acc: 0.0448\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 2s 84us/step - loss: 3.1943 - acc: 0.0421 - val_loss: 3.1809 - val_acc: 0.0448\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1893 - acc: 0.0434 - val_loss: 3.1787 - val_acc: 0.0448\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1886 - acc: 0.0402 - val_loss: 3.1775 - val_acc: 0.0418\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19218/19218 [==============================] - 2s 88us/step - loss: 3.1837 - acc: 0.0431 - val_loss: 3.1769 - val_acc: 0.0418\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1822 - acc: 0.0430 - val_loss: 3.1764 - val_acc: 0.0418\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1802 - acc: 0.0438 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1792 - acc: 0.0451 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1788 - acc: 0.0461 - val_loss: 3.1760 - val_acc: 0.0414\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1783 - acc: 0.0449 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1788 - acc: 0.0440 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1777 - acc: 0.0460 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1773 - acc: 0.0475 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1769 - acc: 0.0458 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1769 - acc: 0.0462 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1769 - acc: 0.0463 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1769 - acc: 0.0469 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1774 - acc: 0.0460 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1767 - acc: 0.0458 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 2s 84us/step - loss: 3.1766 - acc: 0.0445 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 2s 84us/step - loss: 3.1766 - acc: 0.0473 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1760 - acc: 0.0465 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1766 - acc: 0.0454 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1766 - acc: 0.0489 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1763 - acc: 0.0468 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1763 - acc: 0.0451 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1759 - acc: 0.0475 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1761 - acc: 0.0469 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 2s 87us/step - loss: 3.1759 - acc: 0.0478 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1762 - acc: 0.0478 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1761 - acc: 0.0480 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1763 - acc: 0.0433 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1762 - acc: 0.0449 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1757 - acc: 0.0464 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1757 - acc: 0.0460 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1760 - acc: 0.0454 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 2s 84us/step - loss: 3.1758 - acc: 0.0471 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1757 - acc: 0.0475 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 2s 83us/step - loss: 3.1761 - acc: 0.0466 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1760 - acc: 0.0452 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1761 - acc: 0.0465 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1757 - acc: 0.0459 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 2s 84us/step - loss: 3.1757 - acc: 0.0465 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 2s 84us/step - loss: 3.1756 - acc: 0.0458 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1753 - acc: 0.0455 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1757 - acc: 0.0459 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 2s 85us/step - loss: 3.1758 - acc: 0.0462 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 2s 86us/step - loss: 3.1759 - acc: 0.0438 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "[128, 32, 16, 32, 'sigmoid', 'tanh', 'sigmoid', 'sigmoid', <keras.optimizers.Adam object at 0x7feab4e8cb70>, 128, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 6s 301us/step - loss: 3.1983 - acc: 0.0425 - val_loss: 3.1780 - val_acc: 0.0488\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1872 - acc: 0.0424 - val_loss: 3.1765 - val_acc: 0.0418\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1809 - acc: 0.0418 - val_loss: 3.1767 - val_acc: 0.0418\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1809 - acc: 0.0442 - val_loss: 3.1767 - val_acc: 0.0418\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1800 - acc: 0.0425 - val_loss: 3.1765 - val_acc: 0.0418\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1797 - acc: 0.0452 - val_loss: 3.1764 - val_acc: 0.0418\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.1799 - acc: 0.0439 - val_loss: 3.1766 - val_acc: 0.0418\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1791 - acc: 0.0426 - val_loss: 3.1757 - val_acc: 0.0488\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 3s 151us/step - loss: 3.1776 - acc: 0.0479 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1779 - acc: 0.0429 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1786 - acc: 0.0431 - val_loss: 3.1763 - val_acc: 0.0418\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1776 - acc: 0.0459 - val_loss: 3.1764 - val_acc: 0.0418\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1772 - acc: 0.0456 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1775 - acc: 0.0440 - val_loss: 3.1763 - val_acc: 0.0418\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1771 - acc: 0.0470 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.1775 - acc: 0.0445 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.1766 - acc: 0.0457 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1765 - acc: 0.0432 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 3s 151us/step - loss: 3.1762 - acc: 0.0468 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.1761 - acc: 0.0444 - val_loss: 3.1760 - val_acc: 0.0484\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1765 - acc: 0.0447 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1765 - acc: 0.0463 - val_loss: 3.1760 - val_acc: 0.0484\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1765 - acc: 0.0465 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1767 - acc: 0.0459 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1761 - acc: 0.0459 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 3s 151us/step - loss: 3.1763 - acc: 0.0466 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 3s 151us/step - loss: 3.1766 - acc: 0.0434 - val_loss: 3.1760 - val_acc: 0.0484\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1760 - acc: 0.0444 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 3s 151us/step - loss: 3.1763 - acc: 0.0463 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1762 - acc: 0.0458 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1763 - acc: 0.0465 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.1758 - acc: 0.0481 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 3s 150us/step - loss: 3.1763 - acc: 0.0478 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1761 - acc: 0.0448 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1762 - acc: 0.0471 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1758 - acc: 0.0453 - val_loss: 3.1759 - val_acc: 0.0418\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.1761 - acc: 0.0449 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1760 - acc: 0.0433 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1761 - acc: 0.0443 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 3s 152us/step - loss: 3.1761 - acc: 0.0469 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1763 - acc: 0.0459 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 3s 156us/step - loss: 3.1759 - acc: 0.0474 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1759 - acc: 0.0456 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 3s 155us/step - loss: 3.1760 - acc: 0.0455 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 3s 158us/step - loss: 3.1756 - acc: 0.0452 - val_loss: 3.1759 - val_acc: 0.0418\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 3.1758 - acc: 0.0464 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1762 - acc: 0.0449 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 3s 154us/step - loss: 3.1759 - acc: 0.0457 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1758 - acc: 0.0472 - val_loss: 3.1761 - val_acc: 0.0488\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 3s 153us/step - loss: 3.1759 - acc: 0.0447 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "[128, 64, 16, 64, 'tanh', 'sigmoid', 'sigmoid', 'relu', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 256, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 5s 264us/step - loss: 3.2022 - acc: 0.0424 - val_loss: 3.1869 - val_acc: 0.0429\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1897 - acc: 0.0416 - val_loss: 3.1815 - val_acc: 0.0425\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 3s 132us/step - loss: 3.1855 - acc: 0.0422 - val_loss: 3.1790 - val_acc: 0.0425\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 3s 131us/step - loss: 3.1827 - acc: 0.0429 - val_loss: 3.1777 - val_acc: 0.0425\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1808 - acc: 0.0442 - val_loss: 3.1769 - val_acc: 0.0425\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1798 - acc: 0.0465 - val_loss: 3.1764 - val_acc: 0.0425\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 3s 132us/step - loss: 3.1796 - acc: 0.0432 - val_loss: 3.1762 - val_acc: 0.0488\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 3s 132us/step - loss: 3.1793 - acc: 0.0453 - val_loss: 3.1760 - val_acc: 0.0488\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1786 - acc: 0.0442 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 3s 133us/step - loss: 3.1785 - acc: 0.0446 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1781 - acc: 0.0456 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1768 - acc: 0.0445 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 3s 133us/step - loss: 3.1771 - acc: 0.0454 - val_loss: 3.1757 - val_acc: 0.0488\n",
      "Epoch 14/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1774 - acc: 0.0449 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 3s 132us/step - loss: 3.1770 - acc: 0.0437 - val_loss: 3.1757 - val_acc: 0.0488\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1770 - acc: 0.0455 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 3s 133us/step - loss: 3.1772 - acc: 0.0474 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 3s 133us/step - loss: 3.1760 - acc: 0.0453 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 3s 132us/step - loss: 3.1773 - acc: 0.0442 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1772 - acc: 0.0450 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1768 - acc: 0.0466 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1761 - acc: 0.0446 - val_loss: 3.1758 - val_acc: 0.0488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1766 - acc: 0.0458 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1759 - acc: 0.0456 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1765 - acc: 0.0454 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 3s 132us/step - loss: 3.1767 - acc: 0.0431 - val_loss: 3.1759 - val_acc: 0.0488\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 3s 135us/step - loss: 3.1766 - acc: 0.0480 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 3s 137us/step - loss: 3.1768 - acc: 0.0461 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 3s 134us/step - loss: 3.1762 - acc: 0.0452 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 3s 133us/step - loss: 3.1762 - acc: 0.0457 - val_loss: 3.1758 - val_acc: 0.0488\n",
      "[16, 128, 64, 16, 'relu', 'sigmoid', 'sigmoid', 'relu', <keras.optimizers.Adagrad object at 0x7feab4e8cb38>, 256, 40]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 4s 205us/step - loss: 3.1790 - acc: 0.0417 - val_loss: 3.1768 - val_acc: 0.0418\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1764 - acc: 0.0449 - val_loss: 3.1765 - val_acc: 0.0418\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1761 - acc: 0.0456 - val_loss: 3.1763 - val_acc: 0.0418\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1759 - acc: 0.0458 - val_loss: 3.1762 - val_acc: 0.0488\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1758 - acc: 0.0464 - val_loss: 3.1762 - val_acc: 0.0418\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1757 - acc: 0.0452 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 1s 71us/step - loss: 3.1757 - acc: 0.0459 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1757 - acc: 0.0462 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 1s 71us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1761 - val_acc: 0.0418\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1756 - acc: 0.0454 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1756 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1755 - acc: 0.0465 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 1s 71us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 1s 72us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1755 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 1s 73us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 1s 71us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 3.1754 - acc: 0.0467 - val_loss: 3.1760 - val_acc: 0.0418\n",
      "[128, 128, 32, 128, 'relu', 'relu', 'tanh', 'relu', <keras.optimizers.Adamax object at 0x7feab4e8cf28>, 64, 50]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 8s 409us/step - loss: 2.3187 - acc: 0.3007 - val_loss: 1.2686 - val_acc: 0.6175\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 0.9528 - acc: 0.6921 - val_loss: 0.6076 - val_acc: 0.8191\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.5153 - acc: 0.8415 - val_loss: 0.3813 - val_acc: 0.8934\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 5s 249us/step - loss: 0.2904 - acc: 0.9184 - val_loss: 0.2069 - val_acc: 0.9460\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.1629 - acc: 0.9597 - val_loss: 0.0821 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 5s 247us/step - loss: 0.0874 - acc: 0.9833 - val_loss: 0.0382 - val_acc: 0.9977\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0520 - acc: 0.9918 - val_loss: 0.0211 - val_acc: 0.9989\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 5s 250us/step - loss: 0.0314 - acc: 0.9956 - val_loss: 0.0145 - val_acc: 0.9992\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0209 - acc: 0.9981 - val_loss: 0.0106 - val_acc: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0165 - acc: 0.9980 - val_loss: 0.0045 - val_acc: 0.9999\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0115 - acc: 0.9986 - val_loss: 0.0045 - val_acc: 0.9999\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0083 - acc: 0.9994 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 0.0063 - val_acc: 0.9995\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0051 - acc: 0.9997 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.0051 - acc: 0.9997 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0040 - acc: 0.9995 - val_loss: 9.8632e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.0029 - acc: 0.9999 - val_loss: 8.1620e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0041 - acc: 0.9996 - val_loss: 7.0008e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.0026 - acc: 0.9999 - val_loss: 6.8553e-04 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0024 - acc: 0.9997 - val_loss: 4.4785e-04 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 3.1390e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0029 - acc: 0.9996 - val_loss: 3.9033e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.0021 - acc: 0.9997 - val_loss: 7.5110e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 5s 250us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.5071e-04 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0021 - val_acc: 0.9996\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 2.0025e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 2.9166e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 5s 249us/step - loss: 6.6919e-04 - acc: 1.0000 - val_loss: 1.7640e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 5s 250us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 1.9431e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 5.5402e-04 - acc: 1.0000 - val_loss: 1.9660e-04 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 9.3372e-04 - acc: 0.9999 - val_loss: 2.4521e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 5.5007e-04 - acc: 1.0000 - val_loss: 2.6666e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 4.9679e-04 - acc: 0.9999 - val_loss: 0.0027 - val_acc: 0.9992\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 1.0072e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 3.4862e-04 - acc: 1.0000 - val_loss: 8.6762e-05 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 5.8708e-04 - acc: 0.9999 - val_loss: 1.0503e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 3.9645e-04 - acc: 1.0000 - val_loss: 8.1866e-05 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 8.5515e-04 - acc: 0.9999 - val_loss: 3.5607e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 2.8440e-04 - acc: 1.0000 - val_loss: 7.5050e-05 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 8.5168e-05 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 3.9796e-04 - acc: 1.0000 - val_loss: 8.0535e-05 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 2.3851e-04 - acc: 1.0000 - val_loss: 5.6754e-05 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 2.6036e-04 - acc: 1.0000 - val_loss: 1.0279e-04 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 5.3666e-04 - acc: 0.9999 - val_loss: 1.6564e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 2.8176e-04 - acc: 1.0000 - val_loss: 5.8434e-05 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 8.8883e-04 - acc: 0.9997 - val_loss: 5.2996e-04 - val_acc: 0.9999\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 9.0302e-04 - acc: 0.9998 - val_loss: 1.2180e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 1.5470e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 2.2435e-04 - acc: 1.0000 - val_loss: 6.6548e-05 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 1.9531e-04 - acc: 1.0000 - val_loss: 5.0614e-05 - val_acc: 1.0000\n",
      "[16, 64, 16, 32, 'relu', 'tanh', 'relu', 'tanh', <keras.optimizers.SGD object at 0x7feab4ecfb38>, 64, 30]\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/30\n",
      "19218/19218 [==============================] - 6s 291us/step - loss: 3.1778 - acc: 0.0460 - val_loss: 3.1752 - val_acc: 0.0568\n",
      "Epoch 2/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1741 - acc: 0.0528 - val_loss: 3.1727 - val_acc: 0.0516\n",
      "Epoch 3/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1712 - acc: 0.0580 - val_loss: 3.1697 - val_acc: 0.0473\n",
      "Epoch 4/30\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 3.1680 - acc: 0.0623 - val_loss: 3.1661 - val_acc: 0.0504\n",
      "Epoch 5/30\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 3.1638 - acc: 0.0745 - val_loss: 3.1606 - val_acc: 0.0968\n",
      "Epoch 6/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1564 - acc: 0.0893 - val_loss: 3.1514 - val_acc: 0.1073\n",
      "Epoch 7/30\n",
      "19218/19218 [==============================] - 3s 145us/step - loss: 3.1429 - acc: 0.1062 - val_loss: 3.1338 - val_acc: 0.1255\n",
      "Epoch 8/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.1150 - acc: 0.1115 - val_loss: 3.0923 - val_acc: 0.1295\n",
      "Epoch 9/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 3.0583 - acc: 0.1141 - val_loss: 3.0184 - val_acc: 0.1253\n",
      "Epoch 10/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 2.9721 - acc: 0.1182 - val_loss: 2.9178 - val_acc: 0.1298\n",
      "Epoch 11/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 2.8819 - acc: 0.1301 - val_loss: 2.8199 - val_acc: 0.1503\n",
      "Epoch 12/30\n",
      "19218/19218 [==============================] - 3s 145us/step - loss: 2.7823 - acc: 0.1545 - val_loss: 2.7108 - val_acc: 0.1720\n",
      "Epoch 13/30\n",
      "19218/19218 [==============================] - 3s 144us/step - loss: 2.6717 - acc: 0.1849 - val_loss: 2.5785 - val_acc: 0.2190\n",
      "Epoch 14/30\n",
      "19218/19218 [==============================] - 3s 144us/step - loss: 2.5252 - acc: 0.2263 - val_loss: 2.4199 - val_acc: 0.2709\n",
      "Epoch 15/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 2.3595 - acc: 0.2725 - val_loss: 2.3151 - val_acc: 0.2757\n",
      "Epoch 16/30\n",
      "19218/19218 [==============================] - 3s 146us/step - loss: 2.2042 - acc: 0.3093 - val_loss: 2.1470 - val_acc: 0.3019\n",
      "Epoch 17/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 2.0690 - acc: 0.3444 - val_loss: 2.0963 - val_acc: 0.3368\n",
      "Epoch 18/30\n",
      "19218/19218 [==============================] - 3s 144us/step - loss: 1.9495 - acc: 0.3780 - val_loss: 1.8349 - val_acc: 0.4168\n",
      "Epoch 19/30\n",
      "19218/19218 [==============================] - 3s 144us/step - loss: 1.8332 - acc: 0.4106 - val_loss: 1.7444 - val_acc: 0.4517\n",
      "Epoch 20/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 1.7352 - acc: 0.4455 - val_loss: 1.7255 - val_acc: 0.4405\n",
      "Epoch 21/30\n",
      "19218/19218 [==============================] - 3s 146us/step - loss: 1.6253 - acc: 0.4797 - val_loss: 1.5004 - val_acc: 0.5385\n",
      "Epoch 22/30\n",
      "19218/19218 [==============================] - 3s 145us/step - loss: 1.5271 - acc: 0.5186 - val_loss: 1.3889 - val_acc: 0.5785\n",
      "Epoch 23/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 1.4268 - acc: 0.5532 - val_loss: 1.3030 - val_acc: 0.6043\n",
      "Epoch 24/30\n",
      "19218/19218 [==============================] - 3s 145us/step - loss: 1.3318 - acc: 0.5845 - val_loss: 1.4996 - val_acc: 0.5134\n",
      "Epoch 25/30\n",
      "19218/19218 [==============================] - 3s 144us/step - loss: 1.2373 - acc: 0.6166 - val_loss: 1.1062 - val_acc: 0.6833\n",
      "Epoch 26/30\n",
      "19218/19218 [==============================] - 3s 142us/step - loss: 1.1486 - acc: 0.6459 - val_loss: 1.1576 - val_acc: 0.6655\n",
      "Epoch 27/30\n",
      "19218/19218 [==============================] - 3s 144us/step - loss: 1.0713 - acc: 0.6725 - val_loss: 1.0218 - val_acc: 0.6862\n",
      "Epoch 28/30\n",
      "19218/19218 [==============================] - 3s 145us/step - loss: 1.0020 - acc: 0.6958 - val_loss: 0.9249 - val_acc: 0.7421\n",
      "Epoch 29/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 0.9366 - acc: 0.7169 - val_loss: 0.8252 - val_acc: 0.7797\n",
      "Epoch 30/30\n",
      "19218/19218 [==============================] - 3s 143us/step - loss: 0.8837 - acc: 0.7388 - val_loss: 0.9919 - val_acc: 0.6856\n"
     ]
    }
   ],
   "source": [
    "while(count<30):\n",
    "    newGene = newGenClass()\n",
    "    newGene.crossover()\n",
    "    Mutated = newGene.mutation()\n",
    "    print(Mutated)\n",
    "    if(Mutated in total_tries):\n",
    "        pass\n",
    "    else:\n",
    "        count+=1\n",
    "        total_tries.append(Mutated)\n",
    "        run = Modelcnn(x_train,y_train,x_test,y_test,Mutated[0],Mutated[1],Mutated[2],Mutated[3],Mutated[4],Mutated[5],Mutated[6],Mutated[7],Mutated[8],Mutated[9],Mutated[10])\n",
    "        run.createModel()\n",
    "        new_accuracy=run.predict(test_images,test_labels)\n",
    "        acckeys.append(Mutated)\n",
    "        accvals.append(new_accuracy)\n",
    "        if(new_accuracy>accuracy):\n",
    "            accuracy=new_accuracy\n",
    "            best_hyperparameters=Mutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "783a9a9c7594589686a3079a524eb19429653338"
   },
   "outputs": [],
   "source": [
    "for i in range(len(accvals)):\n",
    "    for j in range(len(accvals)):\n",
    "        if(accvals[i]>accvals[j]):\n",
    "            accvals[i],accvals[j]=accvals[j],accvals[i]\n",
    "            acckeys[i],acckeys[j]=acckeys[j],acckeys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "cb18add60249c85fe7d100e0a861c51999718c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 8s 431us/step - loss: 2.6019 - acc: 0.2175 - val_loss: 1.6021 - val_acc: 0.5507\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 1.2404 - acc: 0.5950 - val_loss: 0.8467 - val_acc: 0.7481\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 5s 244us/step - loss: 0.7617 - acc: 0.7516 - val_loss: 0.5177 - val_acc: 0.8474\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 5s 243us/step - loss: 0.4974 - acc: 0.8426 - val_loss: 0.3680 - val_acc: 0.8890\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 5s 240us/step - loss: 0.3287 - acc: 0.9014 - val_loss: 0.2009 - val_acc: 0.9535\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 0.2130 - acc: 0.9406 - val_loss: 0.1350 - val_acc: 0.9695\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 5s 238us/step - loss: 0.1413 - acc: 0.9648 - val_loss: 0.0935 - val_acc: 0.9820\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 5s 240us/step - loss: 0.0917 - acc: 0.9802 - val_loss: 0.0450 - val_acc: 0.9949\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 0.0624 - acc: 0.9880 - val_loss: 0.0263 - val_acc: 0.9984\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 5s 238us/step - loss: 0.0434 - acc: 0.9929 - val_loss: 0.0259 - val_acc: 0.9978\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 0.0314 - acc: 0.9959 - val_loss: 0.0167 - val_acc: 0.9983\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 5s 237us/step - loss: 0.0273 - acc: 0.9961 - val_loss: 0.0130 - val_acc: 0.9993\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 0.0210 - acc: 0.9973 - val_loss: 0.0060 - val_acc: 0.9999\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 5s 237us/step - loss: 0.0141 - acc: 0.9985 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 5s 237us/step - loss: 0.0134 - acc: 0.9983 - val_loss: 0.0057 - val_acc: 0.9998\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 5s 238us/step - loss: 0.0098 - acc: 0.9990 - val_loss: 0.0069 - val_acc: 0.9989\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 5s 237us/step - loss: 0.0110 - acc: 0.9983 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 5s 241us/step - loss: 0.0059 - acc: 0.9996 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 5s 236us/step - loss: 0.0068 - acc: 0.9992 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 5s 236us/step - loss: 0.0061 - acc: 0.9993 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 5s 237us/step - loss: 0.0052 - acc: 0.9997 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 5s 239us/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0152 - val_acc: 0.9964\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 4s 233us/step - loss: 0.0035 - acc: 0.9996 - val_loss: 8.0257e-04 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 5s 234us/step - loss: 0.0036 - acc: 0.9996 - val_loss: 6.8463e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 5s 236us/step - loss: 0.0041 - acc: 0.9994 - val_loss: 6.3723e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 5s 236us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 4s 234us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 6.1222e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 0.0027 - acc: 0.9998 - val_loss: 4.7166e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.0012 - val_acc: 0.9996\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 4s 233us/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.8058e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 4s 231us/step - loss: 0.0020 - acc: 0.9998 - val_loss: 2.6873e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 4s 231us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 2.7519e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 4s 234us/step - loss: 0.0023 - acc: 0.9996 - val_loss: 6.6017e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 0.0021 - acc: 0.9998 - val_loss: 3.2243e-04 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 9.1746e-04 - acc: 1.0000 - val_loss: 2.5269e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 5s 237us/step - loss: 9.4346e-04 - acc: 1.0000 - val_loss: 4.1938e-04 - val_acc: 0.9999\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 5s 235us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 2.0202e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 4s 229us/step - loss: 0.0021 - acc: 0.9998 - val_loss: 3.1291e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 4.6107e-04 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 4s 233us/step - loss: 0.0014 - acc: 0.9999 - val_loss: 1.4436e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 1.6027e-04 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 2.9874e-04 - val_acc: 0.9999\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 6.3087e-04 - acc: 1.0000 - val_loss: 1.4103e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 4s 230us/step - loss: 5.0030e-04 - acc: 1.0000 - val_loss: 1.1453e-04 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 4s 228us/step - loss: 7.0454e-04 - acc: 0.9999 - val_loss: 2.4281e-04 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 4s 231us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 1.8906e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 4s 233us/step - loss: 6.7704e-04 - acc: 1.0000 - val_loss: 1.8505e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 4s 232us/step - loss: 7.9929e-04 - acc: 0.9999 - val_loss: 0.0010 - val_acc: 0.9998\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 5s 234us/step - loss: 5.4480e-04 - acc: 1.0000 - val_loss: 1.0973e-04 - val_acc: 1.0000\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 9s 454us/step - loss: 2.3258 - acc: 0.2817 - val_loss: 1.1367 - val_acc: 0.6567\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 0.8713 - acc: 0.7079 - val_loss: 0.4572 - val_acc: 0.8674\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 0.4141 - acc: 0.8663 - val_loss: 0.2441 - val_acc: 0.9256\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.2082 - acc: 0.9404 - val_loss: 0.0930 - val_acc: 0.9817\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 5s 257us/step - loss: 0.1123 - acc: 0.9685 - val_loss: 0.0357 - val_acc: 0.9973\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0622 - acc: 0.9855 - val_loss: 0.0299 - val_acc: 0.9947\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 5s 258us/step - loss: 0.0390 - acc: 0.9918 - val_loss: 0.0107 - val_acc: 0.9999\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 0.0249 - acc: 0.9950 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.0205 - acc: 0.9960 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 0.0149 - acc: 0.9971 - val_loss: 0.0032 - val_acc: 0.9998\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 0.0116 - acc: 0.9978 - val_loss: 0.0031 - val_acc: 0.9998\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0092 - acc: 0.9985 - val_loss: 0.0019 - val_acc: 0.9999\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.0086 - acc: 0.9980 - val_loss: 0.0021 - val_acc: 0.9999\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0070 - acc: 0.9985 - val_loss: 0.0012 - val_acc: 0.9999\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 6.7961e-04 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0046 - acc: 0.9993 - val_loss: 3.7431e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0033 - acc: 0.9995 - val_loss: 0.0020 - val_acc: 0.9998\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0037 - acc: 0.9994 - val_loss: 5.8312e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 3.9239e-04 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 0.0029 - acc: 0.9996 - val_loss: 5.8873e-04 - val_acc: 0.9999\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 0.0020 - acc: 0.9997 - val_loss: 2.0791e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 0.0027 - acc: 0.9995 - val_loss: 5.1821e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 0.0022 - acc: 0.9997 - val_loss: 5.9733e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 7.0394e-04 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.6339e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 1.3964e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 2.3441e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 2.3949e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 8.4783e-05 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 5.0478e-04 - val_acc: 0.9999\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 3.8451e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 5s 248us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 7.4558e-05 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 9.0487e-04 - acc: 0.9999 - val_loss: 1.8489e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 8.7221e-04 - acc: 0.9999 - val_loss: 7.3432e-05 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 7.6714e-05 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 5.7827e-04 - acc: 0.9999 - val_loss: 7.8501e-05 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 4.4363e-05 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 5s 253us/step - loss: 3.1510e-04 - acc: 1.0000 - val_loss: 3.7992e-05 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 5.7091e-04 - acc: 0.9999 - val_loss: 7.7509e-05 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 9.4160e-04 - acc: 0.9998 - val_loss: 3.4679e-05 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 6.3920e-04 - acc: 0.9999 - val_loss: 6.5612e-05 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 5s 256us/step - loss: 2.5340e-04 - acc: 1.0000 - val_loss: 2.7303e-05 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 5s 255us/step - loss: 2.6701e-04 - acc: 1.0000 - val_loss: 3.8042e-05 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 5s 251us/step - loss: 6.9450e-04 - acc: 0.9998 - val_loss: 3.7201e-05 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 2.7570e-04 - acc: 1.0000 - val_loss: 2.5535e-05 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 3.6024e-05 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 9.3595e-04 - acc: 0.9998 - val_loss: 2.5190e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 5s 252us/step - loss: 6.4953e-04 - acc: 0.9998 - val_loss: 2.9517e-05 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 4.6009e-04 - acc: 0.9999 - val_loss: 2.3868e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 5s 254us/step - loss: 4.1182e-04 - acc: 0.9999 - val_loss: 1.9954e-05 - val_acc: 1.0000\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 7s 366us/step - loss: 2.4792 - acc: 0.2248 - val_loss: 1.5490 - val_acc: 0.5291\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 1.2027 - acc: 0.6095 - val_loss: 0.7200 - val_acc: 0.8002\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 0.6098 - acc: 0.8008 - val_loss: 0.3488 - val_acc: 0.9034\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 4s 191us/step - loss: 0.3226 - acc: 0.8978 - val_loss: 0.1548 - val_acc: 0.9662\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.1694 - acc: 0.9505 - val_loss: 0.0749 - val_acc: 0.9880\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0933 - acc: 0.9761 - val_loss: 0.0376 - val_acc: 0.9956\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 0.0537 - acc: 0.9868 - val_loss: 0.0193 - val_acc: 0.9975\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 0.0337 - acc: 0.9927 - val_loss: 0.0083 - val_acc: 0.9995\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 4s 191us/step - loss: 0.0261 - acc: 0.9945 - val_loss: 0.0062 - val_acc: 0.9995\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0187 - acc: 0.9959 - val_loss: 0.0046 - val_acc: 0.9994\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0140 - acc: 0.9976 - val_loss: 0.0026 - val_acc: 0.9999\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0088 - acc: 0.9985 - val_loss: 0.0016 - val_acc: 0.9999\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 0.0101 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 4s 191us/step - loss: 0.0077 - acc: 0.9986 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0062 - acc: 0.9989 - val_loss: 7.0511e-04 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 0.0047 - acc: 0.9993 - val_loss: 9.9913e-04 - val_acc: 0.9999\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0011 - val_acc: 0.9999\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 0.0034 - acc: 0.9996 - val_loss: 9.4286e-04 - val_acc: 0.9998\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 9.4374e-04 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 4s 193us/step - loss: 0.0029 - acc: 0.9996 - val_loss: 6.8728e-04 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 0.0022 - acc: 0.9998 - val_loss: 2.3349e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 4s 187us/step - loss: 0.0041 - acc: 0.9991 - val_loss: 4.8355e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0023 - acc: 0.9996 - val_loss: 1.6812e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0023 - acc: 0.9997 - val_loss: 2.5920e-04 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0025 - acc: 0.9995 - val_loss: 1.9792e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 4s 187us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 2.5976e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0026 - acc: 0.9996 - val_loss: 1.6910e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 2.2900e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 1.2042e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 6.0924e-04 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0019 - acc: 0.9998 - val_loss: 1.2973e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 4s 192us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 1.1974e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 1.3811e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 4s 191us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 3.4390e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 4s 192us/step - loss: 6.2661e-04 - acc: 1.0000 - val_loss: 6.5692e-05 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 4s 191us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 7.7183e-05 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 4s 192us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 7.3925e-05 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 7.4799e-04 - acc: 1.0000 - val_loss: 5.2615e-04 - val_acc: 0.9998\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 7.8461e-05 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 4.9232e-04 - acc: 0.9999 - val_loss: 9.9843e-05 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 5.1098e-04 - acc: 1.0000 - val_loss: 1.3288e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 6.9155e-05 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 7.7757e-04 - acc: 0.9998 - val_loss: 6.0213e-05 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 5.3790e-04 - acc: 0.9999 - val_loss: 1.2495e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 7.4957e-04 - acc: 0.9999 - val_loss: 1.8908e-04 - val_acc: 0.9999\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 7.6624e-05 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 4s 189us/step - loss: 4.1011e-04 - acc: 0.9999 - val_loss: 3.3620e-05 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 4s 188us/step - loss: 9.3186e-04 - acc: 0.9998 - val_loss: 5.9703e-05 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 4s 190us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 7.5945e-05 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 4s 191us/step - loss: 7.4324e-04 - acc: 0.9999 - val_loss: 1.7218e-04 - val_acc: 0.9999\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/40\n",
      "19218/19218 [==============================] - 7s 356us/step - loss: 2.5259 - acc: 0.2332 - val_loss: 1.6706 - val_acc: 0.4945\n",
      "Epoch 2/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 1.3794 - acc: 0.5564 - val_loss: 1.0493 - val_acc: 0.6779\n",
      "Epoch 3/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.9256 - acc: 0.6939 - val_loss: 0.7449 - val_acc: 0.7539\n",
      "Epoch 4/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.6906 - acc: 0.7730 - val_loss: 0.5547 - val_acc: 0.8157\n",
      "Epoch 5/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.5319 - acc: 0.8239 - val_loss: 0.4272 - val_acc: 0.8646\n",
      "Epoch 6/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.4089 - acc: 0.8655 - val_loss: 0.3207 - val_acc: 0.9041\n",
      "Epoch 7/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.2961 - acc: 0.9098 - val_loss: 0.2332 - val_acc: 0.9381\n",
      "Epoch 8/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.2258 - acc: 0.9363 - val_loss: 0.1611 - val_acc: 0.9591\n",
      "Epoch 9/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.1578 - acc: 0.9592 - val_loss: 0.1214 - val_acc: 0.9709\n",
      "Epoch 10/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.1141 - acc: 0.9739 - val_loss: 0.0917 - val_acc: 0.9824\n",
      "Epoch 11/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.0837 - acc: 0.9840 - val_loss: 0.0532 - val_acc: 0.9943\n",
      "Epoch 12/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0585 - acc: 0.9909 - val_loss: 0.0498 - val_acc: 0.9932\n",
      "Epoch 13/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0426 - acc: 0.9941 - val_loss: 0.0273 - val_acc: 0.9982\n",
      "Epoch 14/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0333 - acc: 0.9959 - val_loss: 0.0177 - val_acc: 0.9987\n",
      "Epoch 15/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0243 - acc: 0.9967 - val_loss: 0.0171 - val_acc: 0.9984\n",
      "Epoch 16/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.0194 - acc: 0.9980 - val_loss: 0.0113 - val_acc: 0.9989\n",
      "Epoch 17/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.0187 - acc: 0.9975 - val_loss: 0.0095 - val_acc: 0.9992\n",
      "Epoch 18/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0126 - acc: 0.9991 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Epoch 19/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0121 - acc: 0.9989 - val_loss: 0.0051 - val_acc: 0.9998\n",
      "Epoch 20/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0082 - acc: 0.9996 - val_loss: 0.0066 - val_acc: 0.9999\n",
      "Epoch 21/40\n",
      "19218/19218 [==============================] - 3s 164us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.0095 - val_acc: 0.9978\n",
      "Epoch 22/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0080 - acc: 0.9993 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 23/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.0056 - acc: 0.9999 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 24/40\n",
      "19218/19218 [==============================] - 3s 162us/step - loss: 0.0051 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 0.9995\n",
      "Epoch 25/40\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 26/40\n",
      "19218/19218 [==============================] - 3s 162us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 27/40\n",
      "19218/19218 [==============================] - 3s 162us/step - loss: 0.0046 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 28/40\n",
      "19218/19218 [==============================] - 3s 157us/step - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 29/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0022 - acc: 0.9999 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 30/40\n",
      "19218/19218 [==============================] - 3s 161us/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0011 - val_acc: 0.9999\n",
      "Epoch 31/40\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 0.0025 - acc: 0.9998 - val_loss: 0.0038 - val_acc: 0.9993\n",
      "Epoch 32/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 9.5566e-04 - val_acc: 1.0000\n",
      "Epoch 33/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.4901e-04 - val_acc: 1.0000\n",
      "Epoch 34/40\n",
      "19218/19218 [==============================] - 3s 159us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 7.4603e-04 - val_acc: 1.0000\n",
      "Epoch 35/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.4508e-04 - val_acc: 1.0000\n",
      "Epoch 36/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.0019 - acc: 0.9998 - val_loss: 5.7477e-04 - val_acc: 1.0000\n",
      "Epoch 37/40\n",
      "19218/19218 [==============================] - 3s 160us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 5.2916e-04 - val_acc: 1.0000\n",
      "Epoch 38/40\n",
      "19218/19218 [==============================] - 3s 165us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 4.3712e-04 - val_acc: 1.0000\n",
      "Epoch 39/40\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 40/40\n",
      "19218/19218 [==============================] - 3s 163us/step - loss: 7.5159e-04 - acc: 1.0000 - val_loss: 3.8682e-04 - val_acc: 1.0000\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 5s 269us/step - loss: 3.0758 - acc: 0.0926 - val_loss: 2.7411 - val_acc: 0.1854\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 2.3360 - acc: 0.2848 - val_loss: 1.8513 - val_acc: 0.4913\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 1.6287 - acc: 0.4865 - val_loss: 1.4284 - val_acc: 0.5491\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 1.2778 - acc: 0.5825 - val_loss: 1.0542 - val_acc: 0.6714\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 1.0501 - acc: 0.6491 - val_loss: 0.8850 - val_acc: 0.7209\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.8910 - acc: 0.7068 - val_loss: 0.7499 - val_acc: 0.7681\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.7608 - acc: 0.7490 - val_loss: 0.6479 - val_acc: 0.8041\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.6476 - acc: 0.7911 - val_loss: 0.5799 - val_acc: 0.8161\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.5763 - acc: 0.8150 - val_loss: 0.4789 - val_acc: 0.8594\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.5015 - acc: 0.8407 - val_loss: 0.4119 - val_acc: 0.8825\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.4286 - acc: 0.8691 - val_loss: 0.3665 - val_acc: 0.9069\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.3845 - acc: 0.8811 - val_loss: 0.3374 - val_acc: 0.9026\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 0.3326 - acc: 0.9008 - val_loss: 0.2743 - val_acc: 0.9253\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 0.2924 - acc: 0.9119 - val_loss: 0.2323 - val_acc: 0.9357\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.2522 - acc: 0.9273 - val_loss: 0.1890 - val_acc: 0.9485\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.2145 - acc: 0.9411 - val_loss: 0.1688 - val_acc: 0.9596\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.1922 - acc: 0.9485 - val_loss: 0.1297 - val_acc: 0.9728\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.1653 - acc: 0.9582 - val_loss: 0.1109 - val_acc: 0.9774\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 1s 71us/step - loss: 0.1420 - acc: 0.9665 - val_loss: 0.1081 - val_acc: 0.9785\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.1255 - acc: 0.9714 - val_loss: 0.0815 - val_acc: 0.9877\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.1157 - acc: 0.9731 - val_loss: 0.0745 - val_acc: 0.9888\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0981 - acc: 0.9780 - val_loss: 0.0664 - val_acc: 0.9894\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0844 - acc: 0.9838 - val_loss: 0.0532 - val_acc: 0.9932\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0761 - acc: 0.9849 - val_loss: 0.0477 - val_acc: 0.9934\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 0.0686 - acc: 0.9858 - val_loss: 0.0475 - val_acc: 0.9942\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0593 - acc: 0.9894 - val_loss: 0.0345 - val_acc: 0.9967\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0519 - acc: 0.9912 - val_loss: 0.0323 - val_acc: 0.9966\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0471 - acc: 0.9922 - val_loss: 0.0278 - val_acc: 0.9970\n",
      "Epoch 29/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0429 - acc: 0.9929 - val_loss: 0.0216 - val_acc: 0.9987\n",
      "Epoch 30/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 0.0373 - acc: 0.9941 - val_loss: 0.0210 - val_acc: 0.9984\n",
      "Epoch 31/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0336 - acc: 0.9951 - val_loss: 0.0181 - val_acc: 0.9985\n",
      "Epoch 32/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0302 - acc: 0.9962 - val_loss: 0.0178 - val_acc: 0.9984\n",
      "Epoch 33/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 0.0279 - acc: 0.9959 - val_loss: 0.0137 - val_acc: 0.9993\n",
      "Epoch 34/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0242 - acc: 0.9967 - val_loss: 0.0182 - val_acc: 0.9978\n",
      "Epoch 35/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0252 - acc: 0.9962 - val_loss: 0.0084 - val_acc: 0.9994\n",
      "Epoch 36/50\n",
      "19218/19218 [==============================] - 1s 71us/step - loss: 0.0195 - acc: 0.9980 - val_loss: 0.0080 - val_acc: 0.9995\n",
      "Epoch 37/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0169 - acc: 0.9982 - val_loss: 0.0067 - val_acc: 0.9996\n",
      "Epoch 38/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0156 - acc: 0.9986 - val_loss: 0.0087 - val_acc: 0.9995\n",
      "Epoch 39/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0166 - acc: 0.9979 - val_loss: 0.0087 - val_acc: 0.9994\n",
      "Epoch 40/50\n",
      "19218/19218 [==============================] - 1s 71us/step - loss: 0.0149 - acc: 0.9982 - val_loss: 0.0072 - val_acc: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0143 - acc: 0.9985 - val_loss: 0.0065 - val_acc: 0.9996\n",
      "Epoch 42/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0124 - acc: 0.9989 - val_loss: 0.0039 - val_acc: 0.9998\n",
      "Epoch 43/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 0.0106 - acc: 0.9989 - val_loss: 0.0061 - val_acc: 0.9995\n",
      "Epoch 44/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0098 - acc: 0.9991 - val_loss: 0.0032 - val_acc: 0.9999\n",
      "Epoch 45/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0103 - acc: 0.9986 - val_loss: 0.0031 - val_acc: 0.9998\n",
      "Epoch 46/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0081 - acc: 0.9993 - val_loss: 0.0033 - val_acc: 0.9999\n",
      "Epoch 47/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 0.0090 - acc: 0.9992 - val_loss: 0.0024 - val_acc: 0.9999\n",
      "Epoch 48/50\n",
      "19218/19218 [==============================] - 1s 70us/step - loss: 0.0076 - acc: 0.9992 - val_loss: 0.0036 - val_acc: 0.9995\n",
      "Epoch 49/50\n",
      "19218/19218 [==============================] - 1s 69us/step - loss: 0.0091 - acc: 0.9988 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "19218/19218 [==============================] - 1s 68us/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.0027 - val_acc: 0.9998\n"
     ]
    }
   ],
   "source": [
    "#Applying the Genetic Algorithm\n",
    "nkey1 = acckeys[0]\n",
    "nkey2 = acckeys[1]\n",
    "gen_acc = accvals[0]\n",
    "lest = [nkey1,nkey2]\n",
    "genHyper= acckeys[0]\n",
    "for i in range(5):\n",
    "    newGen = []\n",
    "    for j in range(11):\n",
    "        q1 = random.choice(lest)\n",
    "        newGen.append(q1[j])\n",
    "    run = Modelcnn(x_train,y_train,x_test,y_test,newGen[0],newGen[1],newGen[2],newGen[3],newGen[4],newGen[5],newGen[6],newGen[7],newGen[8],newGen[9],newGen[10])\n",
    "    run.createModel()\n",
    "    new_accuracy=run.predict(test_images,test_labels)\n",
    "    if(new_accuracy>gen_acc):\n",
    "        gen_acc = new_accuracy\n",
    "        genHyper = newGen\n",
    "acckeys.append(genHyper)\n",
    "accvals.append(gen_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "c7cc6cd21e3ca6f3b0bfba8db46e8513b2b6093a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters found using the genetic algorithm are: \n",
      "[128, 128, 32, 128, 'relu', 'tanh', 'relu', 'relu', <keras.optimizers.Adamax object at 0x7feab4e8cf28>, 64, 50]\n",
      "Best Accuracy found using the genetic algorithm for the above parameters are: \n",
      "0.8329615170105967\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameters found using the genetic algorithm are: \")\n",
    "print(genHyper)\n",
    "print(\"Best Accuracy found using the genetic algorithm for the above parameters are: \")\n",
    "print(gen_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "e9539d91ec101086d38283e57b6ec04d1790c9bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Hyperparameters vs Accuracy\")\\nfor i in range(len(accvals)):\\n    print(\"Hyperparameter\",acckeys[i])\\n    print(\"Accuracy\",accvals[i])\\n    print(\"\")\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"Hyperparameters vs Accuracy\")\n",
    "for i in range(len(accvals)):\n",
    "    print(\"Hyperparameter\",acckeys[i])\n",
    "    print(\"Accuracy\",accvals[i])\n",
    "    print(\"\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9cbee48548b74d4342e761b04c0e55922a8b2992"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
